{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc7816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/uih/JYL/Programs/YOLO/\")\n",
    "import torch\n",
    "from models import Yolov5Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0622cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3e377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = Yolov5Small(3, class_num)\n",
    "my_state_dict = yolo.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed20e690",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: focus.conv.weight\t\ttorch.Size([32, 3, 6, 6])\n",
      "1: focus.bn.weight\t\ttorch.Size([32])\n",
      "2: focus.bn.bias\t\ttorch.Size([32])\n",
      "3: focus.bn.running_mean\t\ttorch.Size([32])\n",
      "4: focus.bn.running_var\t\ttorch.Size([32])\n",
      "5: focus.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "6: backbone_stage1_conv.conv.weight\t\ttorch.Size([64, 32, 3, 3])\n",
      "7: backbone_stage1_conv.bn.weight\t\ttorch.Size([64])\n",
      "8: backbone_stage1_conv.bn.bias\t\ttorch.Size([64])\n",
      "9: backbone_stage1_conv.bn.running_mean\t\ttorch.Size([64])\n",
      "10: backbone_stage1_conv.bn.running_var\t\ttorch.Size([64])\n",
      "11: backbone_stage1_conv.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "12: backbone_stage1_bscp.cba1.conv.weight\t\ttorch.Size([32, 64, 1, 1])\n",
      "13: backbone_stage1_bscp.cba1.bn.weight\t\ttorch.Size([32])\n",
      "14: backbone_stage1_bscp.cba1.bn.bias\t\ttorch.Size([32])\n",
      "15: backbone_stage1_bscp.cba1.bn.running_mean\t\ttorch.Size([32])\n",
      "16: backbone_stage1_bscp.cba1.bn.running_var\t\ttorch.Size([32])\n",
      "17: backbone_stage1_bscp.cba1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "18: backbone_stage1_bscp.cba2.conv.weight\t\ttorch.Size([32, 64, 1, 1])\n",
      "19: backbone_stage1_bscp.cba2.bn.weight\t\ttorch.Size([32])\n",
      "20: backbone_stage1_bscp.cba2.bn.bias\t\ttorch.Size([32])\n",
      "21: backbone_stage1_bscp.cba2.bn.running_mean\t\ttorch.Size([32])\n",
      "22: backbone_stage1_bscp.cba2.bn.running_var\t\ttorch.Size([32])\n",
      "23: backbone_stage1_bscp.cba2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "24: backbone_stage1_bscp.cba3.conv.weight\t\ttorch.Size([64, 64, 1, 1])\n",
      "25: backbone_stage1_bscp.cba3.bn.weight\t\ttorch.Size([64])\n",
      "26: backbone_stage1_bscp.cba3.bn.bias\t\ttorch.Size([64])\n",
      "27: backbone_stage1_bscp.cba3.bn.running_mean\t\ttorch.Size([64])\n",
      "28: backbone_stage1_bscp.cba3.bn.running_var\t\ttorch.Size([64])\n",
      "29: backbone_stage1_bscp.cba3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "30: backbone_stage1_bscp.blocks.0.conv_bn_act_1.conv.weight\t\ttorch.Size([32, 32, 1, 1])\n",
      "31: backbone_stage1_bscp.blocks.0.conv_bn_act_1.bn.weight\t\ttorch.Size([32])\n",
      "32: backbone_stage1_bscp.blocks.0.conv_bn_act_1.bn.bias\t\ttorch.Size([32])\n",
      "33: backbone_stage1_bscp.blocks.0.conv_bn_act_1.bn.running_mean\t\ttorch.Size([32])\n",
      "34: backbone_stage1_bscp.blocks.0.conv_bn_act_1.bn.running_var\t\ttorch.Size([32])\n",
      "35: backbone_stage1_bscp.blocks.0.conv_bn_act_1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "36: backbone_stage1_bscp.blocks.0.conv_bn_act_2.conv.weight\t\ttorch.Size([32, 32, 3, 3])\n",
      "37: backbone_stage1_bscp.blocks.0.conv_bn_act_2.bn.weight\t\ttorch.Size([32])\n",
      "38: backbone_stage1_bscp.blocks.0.conv_bn_act_2.bn.bias\t\ttorch.Size([32])\n",
      "39: backbone_stage1_bscp.blocks.0.conv_bn_act_2.bn.running_mean\t\ttorch.Size([32])\n",
      "40: backbone_stage1_bscp.blocks.0.conv_bn_act_2.bn.running_var\t\ttorch.Size([32])\n",
      "41: backbone_stage1_bscp.blocks.0.conv_bn_act_2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "42: backbone_stage2_conv.conv.weight\t\ttorch.Size([128, 64, 3, 3])\n",
      "43: backbone_stage2_conv.bn.weight\t\ttorch.Size([128])\n",
      "44: backbone_stage2_conv.bn.bias\t\ttorch.Size([128])\n",
      "45: backbone_stage2_conv.bn.running_mean\t\ttorch.Size([128])\n",
      "46: backbone_stage2_conv.bn.running_var\t\ttorch.Size([128])\n",
      "47: backbone_stage2_conv.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "48: backbone_stage2_bscp.cba1.conv.weight\t\ttorch.Size([64, 128, 1, 1])\n",
      "49: backbone_stage2_bscp.cba1.bn.weight\t\ttorch.Size([64])\n",
      "50: backbone_stage2_bscp.cba1.bn.bias\t\ttorch.Size([64])\n",
      "51: backbone_stage2_bscp.cba1.bn.running_mean\t\ttorch.Size([64])\n",
      "52: backbone_stage2_bscp.cba1.bn.running_var\t\ttorch.Size([64])\n",
      "53: backbone_stage2_bscp.cba1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "54: backbone_stage2_bscp.cba2.conv.weight\t\ttorch.Size([64, 128, 1, 1])\n",
      "55: backbone_stage2_bscp.cba2.bn.weight\t\ttorch.Size([64])\n",
      "56: backbone_stage2_bscp.cba2.bn.bias\t\ttorch.Size([64])\n",
      "57: backbone_stage2_bscp.cba2.bn.running_mean\t\ttorch.Size([64])\n",
      "58: backbone_stage2_bscp.cba2.bn.running_var\t\ttorch.Size([64])\n",
      "59: backbone_stage2_bscp.cba2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "60: backbone_stage2_bscp.cba3.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "61: backbone_stage2_bscp.cba3.bn.weight\t\ttorch.Size([128])\n",
      "62: backbone_stage2_bscp.cba3.bn.bias\t\ttorch.Size([128])\n",
      "63: backbone_stage2_bscp.cba3.bn.running_mean\t\ttorch.Size([128])\n",
      "64: backbone_stage2_bscp.cba3.bn.running_var\t\ttorch.Size([128])\n",
      "65: backbone_stage2_bscp.cba3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "66: backbone_stage2_bscp.blocks.0.conv_bn_act_1.conv.weight\t\ttorch.Size([64, 64, 1, 1])\n",
      "67: backbone_stage2_bscp.blocks.0.conv_bn_act_1.bn.weight\t\ttorch.Size([64])\n",
      "68: backbone_stage2_bscp.blocks.0.conv_bn_act_1.bn.bias\t\ttorch.Size([64])\n",
      "69: backbone_stage2_bscp.blocks.0.conv_bn_act_1.bn.running_mean\t\ttorch.Size([64])\n",
      "70: backbone_stage2_bscp.blocks.0.conv_bn_act_1.bn.running_var\t\ttorch.Size([64])\n",
      "71: backbone_stage2_bscp.blocks.0.conv_bn_act_1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "72: backbone_stage2_bscp.blocks.0.conv_bn_act_2.conv.weight\t\ttorch.Size([64, 64, 3, 3])\n",
      "73: backbone_stage2_bscp.blocks.0.conv_bn_act_2.bn.weight\t\ttorch.Size([64])\n",
      "74: backbone_stage2_bscp.blocks.0.conv_bn_act_2.bn.bias\t\ttorch.Size([64])\n",
      "75: backbone_stage2_bscp.blocks.0.conv_bn_act_2.bn.running_mean\t\ttorch.Size([64])\n",
      "76: backbone_stage2_bscp.blocks.0.conv_bn_act_2.bn.running_var\t\ttorch.Size([64])\n",
      "77: backbone_stage2_bscp.blocks.0.conv_bn_act_2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "78: backbone_stage2_bscp.blocks.1.conv_bn_act_1.conv.weight\t\ttorch.Size([64, 64, 1, 1])\n",
      "79: backbone_stage2_bscp.blocks.1.conv_bn_act_1.bn.weight\t\ttorch.Size([64])\n",
      "80: backbone_stage2_bscp.blocks.1.conv_bn_act_1.bn.bias\t\ttorch.Size([64])\n",
      "81: backbone_stage2_bscp.blocks.1.conv_bn_act_1.bn.running_mean\t\ttorch.Size([64])\n",
      "82: backbone_stage2_bscp.blocks.1.conv_bn_act_1.bn.running_var\t\ttorch.Size([64])\n",
      "83: backbone_stage2_bscp.blocks.1.conv_bn_act_1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "84: backbone_stage2_bscp.blocks.1.conv_bn_act_2.conv.weight\t\ttorch.Size([64, 64, 3, 3])\n",
      "85: backbone_stage2_bscp.blocks.1.conv_bn_act_2.bn.weight\t\ttorch.Size([64])\n",
      "86: backbone_stage2_bscp.blocks.1.conv_bn_act_2.bn.bias\t\ttorch.Size([64])\n",
      "87: backbone_stage2_bscp.blocks.1.conv_bn_act_2.bn.running_mean\t\ttorch.Size([64])\n",
      "88: backbone_stage2_bscp.blocks.1.conv_bn_act_2.bn.running_var\t\ttorch.Size([64])\n",
      "89: backbone_stage2_bscp.blocks.1.conv_bn_act_2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "90: backbone_stage3_conv.conv.weight\t\ttorch.Size([256, 128, 3, 3])\n",
      "91: backbone_stage3_conv.bn.weight\t\ttorch.Size([256])\n",
      "92: backbone_stage3_conv.bn.bias\t\ttorch.Size([256])\n",
      "93: backbone_stage3_conv.bn.running_mean\t\ttorch.Size([256])\n",
      "94: backbone_stage3_conv.bn.running_var\t\ttorch.Size([256])\n",
      "95: backbone_stage3_conv.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "96: backbone_stage3_bscp.cba1.conv.weight\t\ttorch.Size([128, 256, 1, 1])\n",
      "97: backbone_stage3_bscp.cba1.bn.weight\t\ttorch.Size([128])\n",
      "98: backbone_stage3_bscp.cba1.bn.bias\t\ttorch.Size([128])\n",
      "99: backbone_stage3_bscp.cba1.bn.running_mean\t\ttorch.Size([128])\n",
      "100: backbone_stage3_bscp.cba1.bn.running_var\t\ttorch.Size([128])\n",
      "101: backbone_stage3_bscp.cba1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "102: backbone_stage3_bscp.cba2.conv.weight\t\ttorch.Size([128, 256, 1, 1])\n",
      "103: backbone_stage3_bscp.cba2.bn.weight\t\ttorch.Size([128])\n",
      "104: backbone_stage3_bscp.cba2.bn.bias\t\ttorch.Size([128])\n",
      "105: backbone_stage3_bscp.cba2.bn.running_mean\t\ttorch.Size([128])\n",
      "106: backbone_stage3_bscp.cba2.bn.running_var\t\ttorch.Size([128])\n",
      "107: backbone_stage3_bscp.cba2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "108: backbone_stage3_bscp.cba3.conv.weight\t\ttorch.Size([256, 256, 1, 1])\n",
      "109: backbone_stage3_bscp.cba3.bn.weight\t\ttorch.Size([256])\n",
      "110: backbone_stage3_bscp.cba3.bn.bias\t\ttorch.Size([256])\n",
      "111: backbone_stage3_bscp.cba3.bn.running_mean\t\ttorch.Size([256])\n",
      "112: backbone_stage3_bscp.cba3.bn.running_var\t\ttorch.Size([256])\n",
      "113: backbone_stage3_bscp.cba3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "114: backbone_stage3_bscp.blocks.0.conv_bn_act_1.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "115: backbone_stage3_bscp.blocks.0.conv_bn_act_1.bn.weight\t\ttorch.Size([128])\n",
      "116: backbone_stage3_bscp.blocks.0.conv_bn_act_1.bn.bias\t\ttorch.Size([128])\n",
      "117: backbone_stage3_bscp.blocks.0.conv_bn_act_1.bn.running_mean\t\ttorch.Size([128])\n",
      "118: backbone_stage3_bscp.blocks.0.conv_bn_act_1.bn.running_var\t\ttorch.Size([128])\n",
      "119: backbone_stage3_bscp.blocks.0.conv_bn_act_1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "120: backbone_stage3_bscp.blocks.0.conv_bn_act_2.conv.weight\t\ttorch.Size([128, 128, 3, 3])\n",
      "121: backbone_stage3_bscp.blocks.0.conv_bn_act_2.bn.weight\t\ttorch.Size([128])\n",
      "122: backbone_stage3_bscp.blocks.0.conv_bn_act_2.bn.bias\t\ttorch.Size([128])\n",
      "123: backbone_stage3_bscp.blocks.0.conv_bn_act_2.bn.running_mean\t\ttorch.Size([128])\n",
      "124: backbone_stage3_bscp.blocks.0.conv_bn_act_2.bn.running_var\t\ttorch.Size([128])\n",
      "125: backbone_stage3_bscp.blocks.0.conv_bn_act_2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "126: backbone_stage3_bscp.blocks.1.conv_bn_act_1.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "127: backbone_stage3_bscp.blocks.1.conv_bn_act_1.bn.weight\t\ttorch.Size([128])\n",
      "128: backbone_stage3_bscp.blocks.1.conv_bn_act_1.bn.bias\t\ttorch.Size([128])\n",
      "129: backbone_stage3_bscp.blocks.1.conv_bn_act_1.bn.running_mean\t\ttorch.Size([128])\n",
      "130: backbone_stage3_bscp.blocks.1.conv_bn_act_1.bn.running_var\t\ttorch.Size([128])\n",
      "131: backbone_stage3_bscp.blocks.1.conv_bn_act_1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "132: backbone_stage3_bscp.blocks.1.conv_bn_act_2.conv.weight\t\ttorch.Size([128, 128, 3, 3])\n",
      "133: backbone_stage3_bscp.blocks.1.conv_bn_act_2.bn.weight\t\ttorch.Size([128])\n",
      "134: backbone_stage3_bscp.blocks.1.conv_bn_act_2.bn.bias\t\ttorch.Size([128])\n",
      "135: backbone_stage3_bscp.blocks.1.conv_bn_act_2.bn.running_mean\t\ttorch.Size([128])\n",
      "136: backbone_stage3_bscp.blocks.1.conv_bn_act_2.bn.running_var\t\ttorch.Size([128])\n",
      "137: backbone_stage3_bscp.blocks.1.conv_bn_act_2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "138: backbone_stage3_bscp.blocks.2.conv_bn_act_1.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "139: backbone_stage3_bscp.blocks.2.conv_bn_act_1.bn.weight\t\ttorch.Size([128])\n",
      "140: backbone_stage3_bscp.blocks.2.conv_bn_act_1.bn.bias\t\ttorch.Size([128])\n",
      "141: backbone_stage3_bscp.blocks.2.conv_bn_act_1.bn.running_mean\t\ttorch.Size([128])\n",
      "142: backbone_stage3_bscp.blocks.2.conv_bn_act_1.bn.running_var\t\ttorch.Size([128])\n",
      "143: backbone_stage3_bscp.blocks.2.conv_bn_act_1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "144: backbone_stage3_bscp.blocks.2.conv_bn_act_2.conv.weight\t\ttorch.Size([128, 128, 3, 3])\n",
      "145: backbone_stage3_bscp.blocks.2.conv_bn_act_2.bn.weight\t\ttorch.Size([128])\n",
      "146: backbone_stage3_bscp.blocks.2.conv_bn_act_2.bn.bias\t\ttorch.Size([128])\n",
      "147: backbone_stage3_bscp.blocks.2.conv_bn_act_2.bn.running_mean\t\ttorch.Size([128])\n",
      "148: backbone_stage3_bscp.blocks.2.conv_bn_act_2.bn.running_var\t\ttorch.Size([128])\n",
      "149: backbone_stage3_bscp.blocks.2.conv_bn_act_2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "150: backbone_stage4_conv.conv.weight\t\ttorch.Size([512, 256, 3, 3])\n",
      "151: backbone_stage4_conv.bn.weight\t\ttorch.Size([512])\n",
      "152: backbone_stage4_conv.bn.bias\t\ttorch.Size([512])\n",
      "153: backbone_stage4_conv.bn.running_mean\t\ttorch.Size([512])\n",
      "154: backbone_stage4_conv.bn.running_var\t\ttorch.Size([512])\n",
      "155: backbone_stage4_conv.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "156: backbone_stage4_bscp.cba1.conv.weight\t\ttorch.Size([256, 512, 1, 1])\n",
      "157: backbone_stage4_bscp.cba1.bn.weight\t\ttorch.Size([256])\n",
      "158: backbone_stage4_bscp.cba1.bn.bias\t\ttorch.Size([256])\n",
      "159: backbone_stage4_bscp.cba1.bn.running_mean\t\ttorch.Size([256])\n",
      "160: backbone_stage4_bscp.cba1.bn.running_var\t\ttorch.Size([256])\n",
      "161: backbone_stage4_bscp.cba1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "162: backbone_stage4_bscp.cba2.conv.weight\t\ttorch.Size([256, 512, 1, 1])\n",
      "163: backbone_stage4_bscp.cba2.bn.weight\t\ttorch.Size([256])\n",
      "164: backbone_stage4_bscp.cba2.bn.bias\t\ttorch.Size([256])\n",
      "165: backbone_stage4_bscp.cba2.bn.running_mean\t\ttorch.Size([256])\n",
      "166: backbone_stage4_bscp.cba2.bn.running_var\t\ttorch.Size([256])\n",
      "167: backbone_stage4_bscp.cba2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "168: backbone_stage4_bscp.cba3.conv.weight\t\ttorch.Size([512, 512, 1, 1])\n",
      "169: backbone_stage4_bscp.cba3.bn.weight\t\ttorch.Size([512])\n",
      "170: backbone_stage4_bscp.cba3.bn.bias\t\ttorch.Size([512])\n",
      "171: backbone_stage4_bscp.cba3.bn.running_mean\t\ttorch.Size([512])\n",
      "172: backbone_stage4_bscp.cba3.bn.running_var\t\ttorch.Size([512])\n",
      "173: backbone_stage4_bscp.cba3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "174: backbone_stage4_bscp.blocks.0.conv_bn_act_1.conv.weight\t\ttorch.Size([256, 256, 1, 1])\n",
      "175: backbone_stage4_bscp.blocks.0.conv_bn_act_1.bn.weight\t\ttorch.Size([256])\n",
      "176: backbone_stage4_bscp.blocks.0.conv_bn_act_1.bn.bias\t\ttorch.Size([256])\n",
      "177: backbone_stage4_bscp.blocks.0.conv_bn_act_1.bn.running_mean\t\ttorch.Size([256])\n",
      "178: backbone_stage4_bscp.blocks.0.conv_bn_act_1.bn.running_var\t\ttorch.Size([256])\n",
      "179: backbone_stage4_bscp.blocks.0.conv_bn_act_1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "180: backbone_stage4_bscp.blocks.0.conv_bn_act_2.conv.weight\t\ttorch.Size([256, 256, 3, 3])\n",
      "181: backbone_stage4_bscp.blocks.0.conv_bn_act_2.bn.weight\t\ttorch.Size([256])\n",
      "182: backbone_stage4_bscp.blocks.0.conv_bn_act_2.bn.bias\t\ttorch.Size([256])\n",
      "183: backbone_stage4_bscp.blocks.0.conv_bn_act_2.bn.running_mean\t\ttorch.Size([256])\n",
      "184: backbone_stage4_bscp.blocks.0.conv_bn_act_2.bn.running_var\t\ttorch.Size([256])\n",
      "185: backbone_stage4_bscp.blocks.0.conv_bn_act_2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "186: backbone_stage4_spp.cba1.conv.weight\t\ttorch.Size([256, 512, 1, 1])\n",
      "187: backbone_stage4_spp.cba1.bn.weight\t\ttorch.Size([256])\n",
      "188: backbone_stage4_spp.cba1.bn.bias\t\ttorch.Size([256])\n",
      "189: backbone_stage4_spp.cba1.bn.running_mean\t\ttorch.Size([256])\n",
      "190: backbone_stage4_spp.cba1.bn.running_var\t\ttorch.Size([256])\n",
      "191: backbone_stage4_spp.cba1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "192: backbone_stage4_spp.cba2.conv.weight\t\ttorch.Size([512, 1024, 1, 1])\n",
      "193: backbone_stage4_spp.cba2.bn.weight\t\ttorch.Size([512])\n",
      "194: backbone_stage4_spp.cba2.bn.bias\t\ttorch.Size([512])\n",
      "195: backbone_stage4_spp.cba2.bn.running_mean\t\ttorch.Size([512])\n",
      "196: backbone_stage4_spp.cba2.bn.running_var\t\ttorch.Size([512])\n",
      "197: backbone_stage4_spp.cba2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "198: head_stage1_conv.conv.weight\t\ttorch.Size([256, 512, 1, 1])\n",
      "199: head_stage1_conv.bn.weight\t\ttorch.Size([256])\n",
      "200: head_stage1_conv.bn.bias\t\ttorch.Size([256])\n",
      "201: head_stage1_conv.bn.running_mean\t\ttorch.Size([256])\n",
      "202: head_stage1_conv.bn.running_var\t\ttorch.Size([256])\n",
      "203: head_stage1_conv.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "204: head_stage1_bscp.cba1.conv.weight\t\ttorch.Size([128, 512, 1, 1])\n",
      "205: head_stage1_bscp.cba1.bn.weight\t\ttorch.Size([128])\n",
      "206: head_stage1_bscp.cba1.bn.bias\t\ttorch.Size([128])\n",
      "207: head_stage1_bscp.cba1.bn.running_mean\t\ttorch.Size([128])\n",
      "208: head_stage1_bscp.cba1.bn.running_var\t\ttorch.Size([128])\n",
      "209: head_stage1_bscp.cba1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "210: head_stage1_bscp.cba2.conv.weight\t\ttorch.Size([128, 512, 1, 1])\n",
      "211: head_stage1_bscp.cba2.bn.weight\t\ttorch.Size([128])\n",
      "212: head_stage1_bscp.cba2.bn.bias\t\ttorch.Size([128])\n",
      "213: head_stage1_bscp.cba2.bn.running_mean\t\ttorch.Size([128])\n",
      "214: head_stage1_bscp.cba2.bn.running_var\t\ttorch.Size([128])\n",
      "215: head_stage1_bscp.cba2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "216: head_stage1_bscp.cba3.conv.weight\t\ttorch.Size([256, 256, 1, 1])\n",
      "217: head_stage1_bscp.cba3.bn.weight\t\ttorch.Size([256])\n",
      "218: head_stage1_bscp.cba3.bn.bias\t\ttorch.Size([256])\n",
      "219: head_stage1_bscp.cba3.bn.running_mean\t\ttorch.Size([256])\n",
      "220: head_stage1_bscp.cba3.bn.running_var\t\ttorch.Size([256])\n",
      "221: head_stage1_bscp.cba3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "222: head_stage1_bscp.blocks.0.conv_bn_act_1.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "223: head_stage1_bscp.blocks.0.conv_bn_act_1.bn.weight\t\ttorch.Size([128])\n",
      "224: head_stage1_bscp.blocks.0.conv_bn_act_1.bn.bias\t\ttorch.Size([128])\n",
      "225: head_stage1_bscp.blocks.0.conv_bn_act_1.bn.running_mean\t\ttorch.Size([128])\n",
      "226: head_stage1_bscp.blocks.0.conv_bn_act_1.bn.running_var\t\ttorch.Size([128])\n",
      "227: head_stage1_bscp.blocks.0.conv_bn_act_1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "228: head_stage1_bscp.blocks.0.conv_bn_act_2.conv.weight\t\ttorch.Size([128, 128, 3, 3])\n",
      "229: head_stage1_bscp.blocks.0.conv_bn_act_2.bn.weight\t\ttorch.Size([128])\n",
      "230: head_stage1_bscp.blocks.0.conv_bn_act_2.bn.bias\t\ttorch.Size([128])\n",
      "231: head_stage1_bscp.blocks.0.conv_bn_act_2.bn.running_mean\t\ttorch.Size([128])\n",
      "232: head_stage1_bscp.blocks.0.conv_bn_act_2.bn.running_var\t\ttorch.Size([128])\n",
      "233: head_stage1_bscp.blocks.0.conv_bn_act_2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "234: head_stage2_conv.conv.weight\t\ttorch.Size([128, 256, 1, 1])\n",
      "235: head_stage2_conv.bn.weight\t\ttorch.Size([128])\n",
      "236: head_stage2_conv.bn.bias\t\ttorch.Size([128])\n",
      "237: head_stage2_conv.bn.running_mean\t\ttorch.Size([128])\n",
      "238: head_stage2_conv.bn.running_var\t\ttorch.Size([128])\n",
      "239: head_stage2_conv.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "240: head_stage2_bscp.cba1.conv.weight\t\ttorch.Size([64, 256, 1, 1])\n",
      "241: head_stage2_bscp.cba1.bn.weight\t\ttorch.Size([64])\n",
      "242: head_stage2_bscp.cba1.bn.bias\t\ttorch.Size([64])\n",
      "243: head_stage2_bscp.cba1.bn.running_mean\t\ttorch.Size([64])\n",
      "244: head_stage2_bscp.cba1.bn.running_var\t\ttorch.Size([64])\n",
      "245: head_stage2_bscp.cba1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "246: head_stage2_bscp.cba2.conv.weight\t\ttorch.Size([64, 256, 1, 1])\n",
      "247: head_stage2_bscp.cba2.bn.weight\t\ttorch.Size([64])\n",
      "248: head_stage2_bscp.cba2.bn.bias\t\ttorch.Size([64])\n",
      "249: head_stage2_bscp.cba2.bn.running_mean\t\ttorch.Size([64])\n",
      "250: head_stage2_bscp.cba2.bn.running_var\t\ttorch.Size([64])\n",
      "251: head_stage2_bscp.cba2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "252: head_stage2_bscp.cba3.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "253: head_stage2_bscp.cba3.bn.weight\t\ttorch.Size([128])\n",
      "254: head_stage2_bscp.cba3.bn.bias\t\ttorch.Size([128])\n",
      "255: head_stage2_bscp.cba3.bn.running_mean\t\ttorch.Size([128])\n",
      "256: head_stage2_bscp.cba3.bn.running_var\t\ttorch.Size([128])\n",
      "257: head_stage2_bscp.cba3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "258: head_stage2_bscp.blocks.0.conv_bn_act_1.conv.weight\t\ttorch.Size([64, 64, 1, 1])\n",
      "259: head_stage2_bscp.blocks.0.conv_bn_act_1.bn.weight\t\ttorch.Size([64])\n",
      "260: head_stage2_bscp.blocks.0.conv_bn_act_1.bn.bias\t\ttorch.Size([64])\n",
      "261: head_stage2_bscp.blocks.0.conv_bn_act_1.bn.running_mean\t\ttorch.Size([64])\n",
      "262: head_stage2_bscp.blocks.0.conv_bn_act_1.bn.running_var\t\ttorch.Size([64])\n",
      "263: head_stage2_bscp.blocks.0.conv_bn_act_1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "264: head_stage2_bscp.blocks.0.conv_bn_act_2.conv.weight\t\ttorch.Size([64, 64, 3, 3])\n",
      "265: head_stage2_bscp.blocks.0.conv_bn_act_2.bn.weight\t\ttorch.Size([64])\n",
      "266: head_stage2_bscp.blocks.0.conv_bn_act_2.bn.bias\t\ttorch.Size([64])\n",
      "267: head_stage2_bscp.blocks.0.conv_bn_act_2.bn.running_mean\t\ttorch.Size([64])\n",
      "268: head_stage2_bscp.blocks.0.conv_bn_act_2.bn.running_var\t\ttorch.Size([64])\n",
      "269: head_stage2_bscp.blocks.0.conv_bn_act_2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "270: head_stage3_conv.conv.weight\t\ttorch.Size([128, 128, 3, 3])\n",
      "271: head_stage3_conv.bn.weight\t\ttorch.Size([128])\n",
      "272: head_stage3_conv.bn.bias\t\ttorch.Size([128])\n",
      "273: head_stage3_conv.bn.running_mean\t\ttorch.Size([128])\n",
      "274: head_stage3_conv.bn.running_var\t\ttorch.Size([128])\n",
      "275: head_stage3_conv.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "276: head_stage3_bscp.cba1.conv.weight\t\ttorch.Size([128, 256, 1, 1])\n",
      "277: head_stage3_bscp.cba1.bn.weight\t\ttorch.Size([128])\n",
      "278: head_stage3_bscp.cba1.bn.bias\t\ttorch.Size([128])\n",
      "279: head_stage3_bscp.cba1.bn.running_mean\t\ttorch.Size([128])\n",
      "280: head_stage3_bscp.cba1.bn.running_var\t\ttorch.Size([128])\n",
      "281: head_stage3_bscp.cba1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "282: head_stage3_bscp.cba2.conv.weight\t\ttorch.Size([128, 256, 1, 1])\n",
      "283: head_stage3_bscp.cba2.bn.weight\t\ttorch.Size([128])\n",
      "284: head_stage3_bscp.cba2.bn.bias\t\ttorch.Size([128])\n",
      "285: head_stage3_bscp.cba2.bn.running_mean\t\ttorch.Size([128])\n",
      "286: head_stage3_bscp.cba2.bn.running_var\t\ttorch.Size([128])\n",
      "287: head_stage3_bscp.cba2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "288: head_stage3_bscp.cba3.conv.weight\t\ttorch.Size([256, 256, 1, 1])\n",
      "289: head_stage3_bscp.cba3.bn.weight\t\ttorch.Size([256])\n",
      "290: head_stage3_bscp.cba3.bn.bias\t\ttorch.Size([256])\n",
      "291: head_stage3_bscp.cba3.bn.running_mean\t\ttorch.Size([256])\n",
      "292: head_stage3_bscp.cba3.bn.running_var\t\ttorch.Size([256])\n",
      "293: head_stage3_bscp.cba3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "294: head_stage3_bscp.blocks.0.conv_bn_act_1.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "295: head_stage3_bscp.blocks.0.conv_bn_act_1.bn.weight\t\ttorch.Size([128])\n",
      "296: head_stage3_bscp.blocks.0.conv_bn_act_1.bn.bias\t\ttorch.Size([128])\n",
      "297: head_stage3_bscp.blocks.0.conv_bn_act_1.bn.running_mean\t\ttorch.Size([128])\n",
      "298: head_stage3_bscp.blocks.0.conv_bn_act_1.bn.running_var\t\ttorch.Size([128])\n",
      "299: head_stage3_bscp.blocks.0.conv_bn_act_1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "300: head_stage3_bscp.blocks.0.conv_bn_act_2.conv.weight\t\ttorch.Size([128, 128, 3, 3])\n",
      "301: head_stage3_bscp.blocks.0.conv_bn_act_2.bn.weight\t\ttorch.Size([128])\n",
      "302: head_stage3_bscp.blocks.0.conv_bn_act_2.bn.bias\t\ttorch.Size([128])\n",
      "303: head_stage3_bscp.blocks.0.conv_bn_act_2.bn.running_mean\t\ttorch.Size([128])\n",
      "304: head_stage3_bscp.blocks.0.conv_bn_act_2.bn.running_var\t\ttorch.Size([128])\n",
      "305: head_stage3_bscp.blocks.0.conv_bn_act_2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "306: head_stage4_conv.conv.weight\t\ttorch.Size([256, 256, 3, 3])\n",
      "307: head_stage4_conv.bn.weight\t\ttorch.Size([256])\n",
      "308: head_stage4_conv.bn.bias\t\ttorch.Size([256])\n",
      "309: head_stage4_conv.bn.running_mean\t\ttorch.Size([256])\n",
      "310: head_stage4_conv.bn.running_var\t\ttorch.Size([256])\n",
      "311: head_stage4_conv.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "312: head_stage4_bscp.cba1.conv.weight\t\ttorch.Size([256, 512, 1, 1])\n",
      "313: head_stage4_bscp.cba1.bn.weight\t\ttorch.Size([256])\n",
      "314: head_stage4_bscp.cba1.bn.bias\t\ttorch.Size([256])\n",
      "315: head_stage4_bscp.cba1.bn.running_mean\t\ttorch.Size([256])\n",
      "316: head_stage4_bscp.cba1.bn.running_var\t\ttorch.Size([256])\n",
      "317: head_stage4_bscp.cba1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "318: head_stage4_bscp.cba2.conv.weight\t\ttorch.Size([256, 512, 1, 1])\n",
      "319: head_stage4_bscp.cba2.bn.weight\t\ttorch.Size([256])\n",
      "320: head_stage4_bscp.cba2.bn.bias\t\ttorch.Size([256])\n",
      "321: head_stage4_bscp.cba2.bn.running_mean\t\ttorch.Size([256])\n",
      "322: head_stage4_bscp.cba2.bn.running_var\t\ttorch.Size([256])\n",
      "323: head_stage4_bscp.cba2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "324: head_stage4_bscp.cba3.conv.weight\t\ttorch.Size([512, 512, 1, 1])\n",
      "325: head_stage4_bscp.cba3.bn.weight\t\ttorch.Size([512])\n",
      "326: head_stage4_bscp.cba3.bn.bias\t\ttorch.Size([512])\n",
      "327: head_stage4_bscp.cba3.bn.running_mean\t\ttorch.Size([512])\n",
      "328: head_stage4_bscp.cba3.bn.running_var\t\ttorch.Size([512])\n",
      "329: head_stage4_bscp.cba3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "330: head_stage4_bscp.blocks.0.conv_bn_act_1.conv.weight\t\ttorch.Size([256, 256, 1, 1])\n",
      "331: head_stage4_bscp.blocks.0.conv_bn_act_1.bn.weight\t\ttorch.Size([256])\n",
      "332: head_stage4_bscp.blocks.0.conv_bn_act_1.bn.bias\t\ttorch.Size([256])\n",
      "333: head_stage4_bscp.blocks.0.conv_bn_act_1.bn.running_mean\t\ttorch.Size([256])\n",
      "334: head_stage4_bscp.blocks.0.conv_bn_act_1.bn.running_var\t\ttorch.Size([256])\n",
      "335: head_stage4_bscp.blocks.0.conv_bn_act_1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "336: head_stage4_bscp.blocks.0.conv_bn_act_2.conv.weight\t\ttorch.Size([256, 256, 3, 3])\n",
      "337: head_stage4_bscp.blocks.0.conv_bn_act_2.bn.weight\t\ttorch.Size([256])\n",
      "338: head_stage4_bscp.blocks.0.conv_bn_act_2.bn.bias\t\ttorch.Size([256])\n",
      "339: head_stage4_bscp.blocks.0.conv_bn_act_2.bn.running_mean\t\ttorch.Size([256])\n",
      "340: head_stage4_bscp.blocks.0.conv_bn_act_2.bn.running_var\t\ttorch.Size([256])\n",
      "341: head_stage4_bscp.blocks.0.conv_bn_act_2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "342: detect.detect_small.weight\t\ttorch.Size([255, 128, 1, 1])\n",
      "343: detect.detect_small.bias\t\ttorch.Size([255])\n",
      "344: detect.detect_mid.weight\t\ttorch.Size([255, 256, 1, 1])\n",
      "345: detect.detect_mid.bias\t\ttorch.Size([255])\n",
      "346: detect.detect_large.weight\t\ttorch.Size([255, 512, 1, 1])\n",
      "347: detect.detect_large.bias\t\ttorch.Size([255])\n"
     ]
    }
   ],
   "source": [
    "my_total_k = []\n",
    "my_total_v = []\n",
    "my_focus_layer = []\n",
    "my_stage_1_conv = []\n",
    "for i, (k, v) in enumerate(my_state_dict.items()):\n",
    "    print(f'{i}: {k}\\t\\t{v.shape}')\n",
    "    my_total_k.append(k)\n",
    "    my_total_v.append(v)\n",
    "    if \"focus\" in k:\n",
    "        my_focus_layer.append(v)\n",
    "        continue\n",
    "    if \"stage1_conv\" in k:\n",
    "        my_stage_1_conv.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597fb691",
   "metadata": {},
   "outputs": [],
   "source": [
    "v5_state_dict = torch.load('/home/uih/JYL/Programs/yolov5_version6/torch_state_dict_yolos.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31fba55",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: model.0.conv.weight\t\ttorch.Size([32, 3, 6, 6])\n",
      "1: model.0.bn.weight\t\ttorch.Size([32])\n",
      "2: model.0.bn.bias\t\ttorch.Size([32])\n",
      "3: model.0.bn.running_mean\t\ttorch.Size([32])\n",
      "4: model.0.bn.running_var\t\ttorch.Size([32])\n",
      "5: model.0.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "6: model.1.conv.weight\t\ttorch.Size([64, 32, 3, 3])\n",
      "7: model.1.bn.weight\t\ttorch.Size([64])\n",
      "8: model.1.bn.bias\t\ttorch.Size([64])\n",
      "9: model.1.bn.running_mean\t\ttorch.Size([64])\n",
      "10: model.1.bn.running_var\t\ttorch.Size([64])\n",
      "11: model.1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "12: model.2.cv1.conv.weight\t\ttorch.Size([32, 64, 1, 1])\n",
      "13: model.2.cv1.bn.weight\t\ttorch.Size([32])\n",
      "14: model.2.cv1.bn.bias\t\ttorch.Size([32])\n",
      "15: model.2.cv1.bn.running_mean\t\ttorch.Size([32])\n",
      "16: model.2.cv1.bn.running_var\t\ttorch.Size([32])\n",
      "17: model.2.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "18: model.2.cv2.conv.weight\t\ttorch.Size([32, 64, 1, 1])\n",
      "19: model.2.cv2.bn.weight\t\ttorch.Size([32])\n",
      "20: model.2.cv2.bn.bias\t\ttorch.Size([32])\n",
      "21: model.2.cv2.bn.running_mean\t\ttorch.Size([32])\n",
      "22: model.2.cv2.bn.running_var\t\ttorch.Size([32])\n",
      "23: model.2.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "24: model.2.cv3.conv.weight\t\ttorch.Size([64, 64, 1, 1])\n",
      "25: model.2.cv3.bn.weight\t\ttorch.Size([64])\n",
      "26: model.2.cv3.bn.bias\t\ttorch.Size([64])\n",
      "27: model.2.cv3.bn.running_mean\t\ttorch.Size([64])\n",
      "28: model.2.cv3.bn.running_var\t\ttorch.Size([64])\n",
      "29: model.2.cv3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "30: model.2.m.0.cv1.conv.weight\t\ttorch.Size([32, 32, 1, 1])\n",
      "31: model.2.m.0.cv1.bn.weight\t\ttorch.Size([32])\n",
      "32: model.2.m.0.cv1.bn.bias\t\ttorch.Size([32])\n",
      "33: model.2.m.0.cv1.bn.running_mean\t\ttorch.Size([32])\n",
      "34: model.2.m.0.cv1.bn.running_var\t\ttorch.Size([32])\n",
      "35: model.2.m.0.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "36: model.2.m.0.cv2.conv.weight\t\ttorch.Size([32, 32, 3, 3])\n",
      "37: model.2.m.0.cv2.bn.weight\t\ttorch.Size([32])\n",
      "38: model.2.m.0.cv2.bn.bias\t\ttorch.Size([32])\n",
      "39: model.2.m.0.cv2.bn.running_mean\t\ttorch.Size([32])\n",
      "40: model.2.m.0.cv2.bn.running_var\t\ttorch.Size([32])\n",
      "41: model.2.m.0.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "42: model.3.conv.weight\t\ttorch.Size([128, 64, 3, 3])\n",
      "43: model.3.bn.weight\t\ttorch.Size([128])\n",
      "44: model.3.bn.bias\t\ttorch.Size([128])\n",
      "45: model.3.bn.running_mean\t\ttorch.Size([128])\n",
      "46: model.3.bn.running_var\t\ttorch.Size([128])\n",
      "47: model.3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "48: model.4.cv1.conv.weight\t\ttorch.Size([64, 128, 1, 1])\n",
      "49: model.4.cv1.bn.weight\t\ttorch.Size([64])\n",
      "50: model.4.cv1.bn.bias\t\ttorch.Size([64])\n",
      "51: model.4.cv1.bn.running_mean\t\ttorch.Size([64])\n",
      "52: model.4.cv1.bn.running_var\t\ttorch.Size([64])\n",
      "53: model.4.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "54: model.4.cv2.conv.weight\t\ttorch.Size([64, 128, 1, 1])\n",
      "55: model.4.cv2.bn.weight\t\ttorch.Size([64])\n",
      "56: model.4.cv2.bn.bias\t\ttorch.Size([64])\n",
      "57: model.4.cv2.bn.running_mean\t\ttorch.Size([64])\n",
      "58: model.4.cv2.bn.running_var\t\ttorch.Size([64])\n",
      "59: model.4.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "60: model.4.cv3.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "61: model.4.cv3.bn.weight\t\ttorch.Size([128])\n",
      "62: model.4.cv3.bn.bias\t\ttorch.Size([128])\n",
      "63: model.4.cv3.bn.running_mean\t\ttorch.Size([128])\n",
      "64: model.4.cv3.bn.running_var\t\ttorch.Size([128])\n",
      "65: model.4.cv3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "66: model.4.m.0.cv1.conv.weight\t\ttorch.Size([64, 64, 1, 1])\n",
      "67: model.4.m.0.cv1.bn.weight\t\ttorch.Size([64])\n",
      "68: model.4.m.0.cv1.bn.bias\t\ttorch.Size([64])\n",
      "69: model.4.m.0.cv1.bn.running_mean\t\ttorch.Size([64])\n",
      "70: model.4.m.0.cv1.bn.running_var\t\ttorch.Size([64])\n",
      "71: model.4.m.0.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "72: model.4.m.0.cv2.conv.weight\t\ttorch.Size([64, 64, 3, 3])\n",
      "73: model.4.m.0.cv2.bn.weight\t\ttorch.Size([64])\n",
      "74: model.4.m.0.cv2.bn.bias\t\ttorch.Size([64])\n",
      "75: model.4.m.0.cv2.bn.running_mean\t\ttorch.Size([64])\n",
      "76: model.4.m.0.cv2.bn.running_var\t\ttorch.Size([64])\n",
      "77: model.4.m.0.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "78: model.4.m.1.cv1.conv.weight\t\ttorch.Size([64, 64, 1, 1])\n",
      "79: model.4.m.1.cv1.bn.weight\t\ttorch.Size([64])\n",
      "80: model.4.m.1.cv1.bn.bias\t\ttorch.Size([64])\n",
      "81: model.4.m.1.cv1.bn.running_mean\t\ttorch.Size([64])\n",
      "82: model.4.m.1.cv1.bn.running_var\t\ttorch.Size([64])\n",
      "83: model.4.m.1.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "84: model.4.m.1.cv2.conv.weight\t\ttorch.Size([64, 64, 3, 3])\n",
      "85: model.4.m.1.cv2.bn.weight\t\ttorch.Size([64])\n",
      "86: model.4.m.1.cv2.bn.bias\t\ttorch.Size([64])\n",
      "87: model.4.m.1.cv2.bn.running_mean\t\ttorch.Size([64])\n",
      "88: model.4.m.1.cv2.bn.running_var\t\ttorch.Size([64])\n",
      "89: model.4.m.1.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "90: model.5.conv.weight\t\ttorch.Size([256, 128, 3, 3])\n",
      "91: model.5.bn.weight\t\ttorch.Size([256])\n",
      "92: model.5.bn.bias\t\ttorch.Size([256])\n",
      "93: model.5.bn.running_mean\t\ttorch.Size([256])\n",
      "94: model.5.bn.running_var\t\ttorch.Size([256])\n",
      "95: model.5.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "96: model.6.cv1.conv.weight\t\ttorch.Size([128, 256, 1, 1])\n",
      "97: model.6.cv1.bn.weight\t\ttorch.Size([128])\n",
      "98: model.6.cv1.bn.bias\t\ttorch.Size([128])\n",
      "99: model.6.cv1.bn.running_mean\t\ttorch.Size([128])\n",
      "100: model.6.cv1.bn.running_var\t\ttorch.Size([128])\n",
      "101: model.6.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "102: model.6.cv2.conv.weight\t\ttorch.Size([128, 256, 1, 1])\n",
      "103: model.6.cv2.bn.weight\t\ttorch.Size([128])\n",
      "104: model.6.cv2.bn.bias\t\ttorch.Size([128])\n",
      "105: model.6.cv2.bn.running_mean\t\ttorch.Size([128])\n",
      "106: model.6.cv2.bn.running_var\t\ttorch.Size([128])\n",
      "107: model.6.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "108: model.6.cv3.conv.weight\t\ttorch.Size([256, 256, 1, 1])\n",
      "109: model.6.cv3.bn.weight\t\ttorch.Size([256])\n",
      "110: model.6.cv3.bn.bias\t\ttorch.Size([256])\n",
      "111: model.6.cv3.bn.running_mean\t\ttorch.Size([256])\n",
      "112: model.6.cv3.bn.running_var\t\ttorch.Size([256])\n",
      "113: model.6.cv3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "114: model.6.m.0.cv1.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "115: model.6.m.0.cv1.bn.weight\t\ttorch.Size([128])\n",
      "116: model.6.m.0.cv1.bn.bias\t\ttorch.Size([128])\n",
      "117: model.6.m.0.cv1.bn.running_mean\t\ttorch.Size([128])\n",
      "118: model.6.m.0.cv1.bn.running_var\t\ttorch.Size([128])\n",
      "119: model.6.m.0.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "120: model.6.m.0.cv2.conv.weight\t\ttorch.Size([128, 128, 3, 3])\n",
      "121: model.6.m.0.cv2.bn.weight\t\ttorch.Size([128])\n",
      "122: model.6.m.0.cv2.bn.bias\t\ttorch.Size([128])\n",
      "123: model.6.m.0.cv2.bn.running_mean\t\ttorch.Size([128])\n",
      "124: model.6.m.0.cv2.bn.running_var\t\ttorch.Size([128])\n",
      "125: model.6.m.0.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "126: model.6.m.1.cv1.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "127: model.6.m.1.cv1.bn.weight\t\ttorch.Size([128])\n",
      "128: model.6.m.1.cv1.bn.bias\t\ttorch.Size([128])\n",
      "129: model.6.m.1.cv1.bn.running_mean\t\ttorch.Size([128])\n",
      "130: model.6.m.1.cv1.bn.running_var\t\ttorch.Size([128])\n",
      "131: model.6.m.1.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "132: model.6.m.1.cv2.conv.weight\t\ttorch.Size([128, 128, 3, 3])\n",
      "133: model.6.m.1.cv2.bn.weight\t\ttorch.Size([128])\n",
      "134: model.6.m.1.cv2.bn.bias\t\ttorch.Size([128])\n",
      "135: model.6.m.1.cv2.bn.running_mean\t\ttorch.Size([128])\n",
      "136: model.6.m.1.cv2.bn.running_var\t\ttorch.Size([128])\n",
      "137: model.6.m.1.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "138: model.6.m.2.cv1.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "139: model.6.m.2.cv1.bn.weight\t\ttorch.Size([128])\n",
      "140: model.6.m.2.cv1.bn.bias\t\ttorch.Size([128])\n",
      "141: model.6.m.2.cv1.bn.running_mean\t\ttorch.Size([128])\n",
      "142: model.6.m.2.cv1.bn.running_var\t\ttorch.Size([128])\n",
      "143: model.6.m.2.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "144: model.6.m.2.cv2.conv.weight\t\ttorch.Size([128, 128, 3, 3])\n",
      "145: model.6.m.2.cv2.bn.weight\t\ttorch.Size([128])\n",
      "146: model.6.m.2.cv2.bn.bias\t\ttorch.Size([128])\n",
      "147: model.6.m.2.cv2.bn.running_mean\t\ttorch.Size([128])\n",
      "148: model.6.m.2.cv2.bn.running_var\t\ttorch.Size([128])\n",
      "149: model.6.m.2.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "150: model.7.conv.weight\t\ttorch.Size([512, 256, 3, 3])\n",
      "151: model.7.bn.weight\t\ttorch.Size([512])\n",
      "152: model.7.bn.bias\t\ttorch.Size([512])\n",
      "153: model.7.bn.running_mean\t\ttorch.Size([512])\n",
      "154: model.7.bn.running_var\t\ttorch.Size([512])\n",
      "155: model.7.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "156: model.8.cv1.conv.weight\t\ttorch.Size([256, 512, 1, 1])\n",
      "157: model.8.cv1.bn.weight\t\ttorch.Size([256])\n",
      "158: model.8.cv1.bn.bias\t\ttorch.Size([256])\n",
      "159: model.8.cv1.bn.running_mean\t\ttorch.Size([256])\n",
      "160: model.8.cv1.bn.running_var\t\ttorch.Size([256])\n",
      "161: model.8.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "162: model.8.cv2.conv.weight\t\ttorch.Size([256, 512, 1, 1])\n",
      "163: model.8.cv2.bn.weight\t\ttorch.Size([256])\n",
      "164: model.8.cv2.bn.bias\t\ttorch.Size([256])\n",
      "165: model.8.cv2.bn.running_mean\t\ttorch.Size([256])\n",
      "166: model.8.cv2.bn.running_var\t\ttorch.Size([256])\n",
      "167: model.8.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "168: model.8.cv3.conv.weight\t\ttorch.Size([512, 512, 1, 1])\n",
      "169: model.8.cv3.bn.weight\t\ttorch.Size([512])\n",
      "170: model.8.cv3.bn.bias\t\ttorch.Size([512])\n",
      "171: model.8.cv3.bn.running_mean\t\ttorch.Size([512])\n",
      "172: model.8.cv3.bn.running_var\t\ttorch.Size([512])\n",
      "173: model.8.cv3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "174: model.8.m.0.cv1.conv.weight\t\ttorch.Size([256, 256, 1, 1])\n",
      "175: model.8.m.0.cv1.bn.weight\t\ttorch.Size([256])\n",
      "176: model.8.m.0.cv1.bn.bias\t\ttorch.Size([256])\n",
      "177: model.8.m.0.cv1.bn.running_mean\t\ttorch.Size([256])\n",
      "178: model.8.m.0.cv1.bn.running_var\t\ttorch.Size([256])\n",
      "179: model.8.m.0.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "180: model.8.m.0.cv2.conv.weight\t\ttorch.Size([256, 256, 3, 3])\n",
      "181: model.8.m.0.cv2.bn.weight\t\ttorch.Size([256])\n",
      "182: model.8.m.0.cv2.bn.bias\t\ttorch.Size([256])\n",
      "183: model.8.m.0.cv2.bn.running_mean\t\ttorch.Size([256])\n",
      "184: model.8.m.0.cv2.bn.running_var\t\ttorch.Size([256])\n",
      "185: model.8.m.0.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "186: model.9.cv1.conv.weight\t\ttorch.Size([256, 512, 1, 1])\n",
      "187: model.9.cv1.bn.weight\t\ttorch.Size([256])\n",
      "188: model.9.cv1.bn.bias\t\ttorch.Size([256])\n",
      "189: model.9.cv1.bn.running_mean\t\ttorch.Size([256])\n",
      "190: model.9.cv1.bn.running_var\t\ttorch.Size([256])\n",
      "191: model.9.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "192: model.9.cv2.conv.weight\t\ttorch.Size([512, 1024, 1, 1])\n",
      "193: model.9.cv2.bn.weight\t\ttorch.Size([512])\n",
      "194: model.9.cv2.bn.bias\t\ttorch.Size([512])\n",
      "195: model.9.cv2.bn.running_mean\t\ttorch.Size([512])\n",
      "196: model.9.cv2.bn.running_var\t\ttorch.Size([512])\n",
      "197: model.9.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "198: model.10.conv.weight\t\ttorch.Size([256, 512, 1, 1])\n",
      "199: model.10.bn.weight\t\ttorch.Size([256])\n",
      "200: model.10.bn.bias\t\ttorch.Size([256])\n",
      "201: model.10.bn.running_mean\t\ttorch.Size([256])\n",
      "202: model.10.bn.running_var\t\ttorch.Size([256])\n",
      "203: model.10.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "204: model.13.cv1.conv.weight\t\ttorch.Size([128, 512, 1, 1])\n",
      "205: model.13.cv1.bn.weight\t\ttorch.Size([128])\n",
      "206: model.13.cv1.bn.bias\t\ttorch.Size([128])\n",
      "207: model.13.cv1.bn.running_mean\t\ttorch.Size([128])\n",
      "208: model.13.cv1.bn.running_var\t\ttorch.Size([128])\n",
      "209: model.13.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "210: model.13.cv2.conv.weight\t\ttorch.Size([128, 512, 1, 1])\n",
      "211: model.13.cv2.bn.weight\t\ttorch.Size([128])\n",
      "212: model.13.cv2.bn.bias\t\ttorch.Size([128])\n",
      "213: model.13.cv2.bn.running_mean\t\ttorch.Size([128])\n",
      "214: model.13.cv2.bn.running_var\t\ttorch.Size([128])\n",
      "215: model.13.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "216: model.13.cv3.conv.weight\t\ttorch.Size([256, 256, 1, 1])\n",
      "217: model.13.cv3.bn.weight\t\ttorch.Size([256])\n",
      "218: model.13.cv3.bn.bias\t\ttorch.Size([256])\n",
      "219: model.13.cv3.bn.running_mean\t\ttorch.Size([256])\n",
      "220: model.13.cv3.bn.running_var\t\ttorch.Size([256])\n",
      "221: model.13.cv3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "222: model.13.m.0.cv1.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "223: model.13.m.0.cv1.bn.weight\t\ttorch.Size([128])\n",
      "224: model.13.m.0.cv1.bn.bias\t\ttorch.Size([128])\n",
      "225: model.13.m.0.cv1.bn.running_mean\t\ttorch.Size([128])\n",
      "226: model.13.m.0.cv1.bn.running_var\t\ttorch.Size([128])\n",
      "227: model.13.m.0.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "228: model.13.m.0.cv2.conv.weight\t\ttorch.Size([128, 128, 3, 3])\n",
      "229: model.13.m.0.cv2.bn.weight\t\ttorch.Size([128])\n",
      "230: model.13.m.0.cv2.bn.bias\t\ttorch.Size([128])\n",
      "231: model.13.m.0.cv2.bn.running_mean\t\ttorch.Size([128])\n",
      "232: model.13.m.0.cv2.bn.running_var\t\ttorch.Size([128])\n",
      "233: model.13.m.0.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "234: model.14.conv.weight\t\ttorch.Size([128, 256, 1, 1])\n",
      "235: model.14.bn.weight\t\ttorch.Size([128])\n",
      "236: model.14.bn.bias\t\ttorch.Size([128])\n",
      "237: model.14.bn.running_mean\t\ttorch.Size([128])\n",
      "238: model.14.bn.running_var\t\ttorch.Size([128])\n",
      "239: model.14.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "240: model.17.cv1.conv.weight\t\ttorch.Size([64, 256, 1, 1])\n",
      "241: model.17.cv1.bn.weight\t\ttorch.Size([64])\n",
      "242: model.17.cv1.bn.bias\t\ttorch.Size([64])\n",
      "243: model.17.cv1.bn.running_mean\t\ttorch.Size([64])\n",
      "244: model.17.cv1.bn.running_var\t\ttorch.Size([64])\n",
      "245: model.17.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "246: model.17.cv2.conv.weight\t\ttorch.Size([64, 256, 1, 1])\n",
      "247: model.17.cv2.bn.weight\t\ttorch.Size([64])\n",
      "248: model.17.cv2.bn.bias\t\ttorch.Size([64])\n",
      "249: model.17.cv2.bn.running_mean\t\ttorch.Size([64])\n",
      "250: model.17.cv2.bn.running_var\t\ttorch.Size([64])\n",
      "251: model.17.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "252: model.17.cv3.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "253: model.17.cv3.bn.weight\t\ttorch.Size([128])\n",
      "254: model.17.cv3.bn.bias\t\ttorch.Size([128])\n",
      "255: model.17.cv3.bn.running_mean\t\ttorch.Size([128])\n",
      "256: model.17.cv3.bn.running_var\t\ttorch.Size([128])\n",
      "257: model.17.cv3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "258: model.17.m.0.cv1.conv.weight\t\ttorch.Size([64, 64, 1, 1])\n",
      "259: model.17.m.0.cv1.bn.weight\t\ttorch.Size([64])\n",
      "260: model.17.m.0.cv1.bn.bias\t\ttorch.Size([64])\n",
      "261: model.17.m.0.cv1.bn.running_mean\t\ttorch.Size([64])\n",
      "262: model.17.m.0.cv1.bn.running_var\t\ttorch.Size([64])\n",
      "263: model.17.m.0.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "264: model.17.m.0.cv2.conv.weight\t\ttorch.Size([64, 64, 3, 3])\n",
      "265: model.17.m.0.cv2.bn.weight\t\ttorch.Size([64])\n",
      "266: model.17.m.0.cv2.bn.bias\t\ttorch.Size([64])\n",
      "267: model.17.m.0.cv2.bn.running_mean\t\ttorch.Size([64])\n",
      "268: model.17.m.0.cv2.bn.running_var\t\ttorch.Size([64])\n",
      "269: model.17.m.0.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "270: model.18.conv.weight\t\ttorch.Size([128, 128, 3, 3])\n",
      "271: model.18.bn.weight\t\ttorch.Size([128])\n",
      "272: model.18.bn.bias\t\ttorch.Size([128])\n",
      "273: model.18.bn.running_mean\t\ttorch.Size([128])\n",
      "274: model.18.bn.running_var\t\ttorch.Size([128])\n",
      "275: model.18.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "276: model.20.cv1.conv.weight\t\ttorch.Size([128, 256, 1, 1])\n",
      "277: model.20.cv1.bn.weight\t\ttorch.Size([128])\n",
      "278: model.20.cv1.bn.bias\t\ttorch.Size([128])\n",
      "279: model.20.cv1.bn.running_mean\t\ttorch.Size([128])\n",
      "280: model.20.cv1.bn.running_var\t\ttorch.Size([128])\n",
      "281: model.20.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "282: model.20.cv2.conv.weight\t\ttorch.Size([128, 256, 1, 1])\n",
      "283: model.20.cv2.bn.weight\t\ttorch.Size([128])\n",
      "284: model.20.cv2.bn.bias\t\ttorch.Size([128])\n",
      "285: model.20.cv2.bn.running_mean\t\ttorch.Size([128])\n",
      "286: model.20.cv2.bn.running_var\t\ttorch.Size([128])\n",
      "287: model.20.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "288: model.20.cv3.conv.weight\t\ttorch.Size([256, 256, 1, 1])\n",
      "289: model.20.cv3.bn.weight\t\ttorch.Size([256])\n",
      "290: model.20.cv3.bn.bias\t\ttorch.Size([256])\n",
      "291: model.20.cv3.bn.running_mean\t\ttorch.Size([256])\n",
      "292: model.20.cv3.bn.running_var\t\ttorch.Size([256])\n",
      "293: model.20.cv3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "294: model.20.m.0.cv1.conv.weight\t\ttorch.Size([128, 128, 1, 1])\n",
      "295: model.20.m.0.cv1.bn.weight\t\ttorch.Size([128])\n",
      "296: model.20.m.0.cv1.bn.bias\t\ttorch.Size([128])\n",
      "297: model.20.m.0.cv1.bn.running_mean\t\ttorch.Size([128])\n",
      "298: model.20.m.0.cv1.bn.running_var\t\ttorch.Size([128])\n",
      "299: model.20.m.0.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "300: model.20.m.0.cv2.conv.weight\t\ttorch.Size([128, 128, 3, 3])\n",
      "301: model.20.m.0.cv2.bn.weight\t\ttorch.Size([128])\n",
      "302: model.20.m.0.cv2.bn.bias\t\ttorch.Size([128])\n",
      "303: model.20.m.0.cv2.bn.running_mean\t\ttorch.Size([128])\n",
      "304: model.20.m.0.cv2.bn.running_var\t\ttorch.Size([128])\n",
      "305: model.20.m.0.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "306: model.21.conv.weight\t\ttorch.Size([256, 256, 3, 3])\n",
      "307: model.21.bn.weight\t\ttorch.Size([256])\n",
      "308: model.21.bn.bias\t\ttorch.Size([256])\n",
      "309: model.21.bn.running_mean\t\ttorch.Size([256])\n",
      "310: model.21.bn.running_var\t\ttorch.Size([256])\n",
      "311: model.21.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "312: model.23.cv1.conv.weight\t\ttorch.Size([256, 512, 1, 1])\n",
      "313: model.23.cv1.bn.weight\t\ttorch.Size([256])\n",
      "314: model.23.cv1.bn.bias\t\ttorch.Size([256])\n",
      "315: model.23.cv1.bn.running_mean\t\ttorch.Size([256])\n",
      "316: model.23.cv1.bn.running_var\t\ttorch.Size([256])\n",
      "317: model.23.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "318: model.23.cv2.conv.weight\t\ttorch.Size([256, 512, 1, 1])\n",
      "319: model.23.cv2.bn.weight\t\ttorch.Size([256])\n",
      "320: model.23.cv2.bn.bias\t\ttorch.Size([256])\n",
      "321: model.23.cv2.bn.running_mean\t\ttorch.Size([256])\n",
      "322: model.23.cv2.bn.running_var\t\ttorch.Size([256])\n",
      "323: model.23.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "324: model.23.cv3.conv.weight\t\ttorch.Size([512, 512, 1, 1])\n",
      "325: model.23.cv3.bn.weight\t\ttorch.Size([512])\n",
      "326: model.23.cv3.bn.bias\t\ttorch.Size([512])\n",
      "327: model.23.cv3.bn.running_mean\t\ttorch.Size([512])\n",
      "328: model.23.cv3.bn.running_var\t\ttorch.Size([512])\n",
      "329: model.23.cv3.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "330: model.23.m.0.cv1.conv.weight\t\ttorch.Size([256, 256, 1, 1])\n",
      "331: model.23.m.0.cv1.bn.weight\t\ttorch.Size([256])\n",
      "332: model.23.m.0.cv1.bn.bias\t\ttorch.Size([256])\n",
      "333: model.23.m.0.cv1.bn.running_mean\t\ttorch.Size([256])\n",
      "334: model.23.m.0.cv1.bn.running_var\t\ttorch.Size([256])\n",
      "335: model.23.m.0.cv1.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "336: model.23.m.0.cv2.conv.weight\t\ttorch.Size([256, 256, 3, 3])\n",
      "337: model.23.m.0.cv2.bn.weight\t\ttorch.Size([256])\n",
      "338: model.23.m.0.cv2.bn.bias\t\ttorch.Size([256])\n",
      "339: model.23.m.0.cv2.bn.running_mean\t\ttorch.Size([256])\n",
      "340: model.23.m.0.cv2.bn.running_var\t\ttorch.Size([256])\n",
      "341: model.23.m.0.cv2.bn.num_batches_tracked\t\ttorch.Size([])\n",
      "343: model.24.m.0.weight\t\ttorch.Size([255, 128, 1, 1])\n",
      "344: model.24.m.0.bias\t\ttorch.Size([255])\n",
      "345: model.24.m.1.weight\t\ttorch.Size([255, 256, 1, 1])\n",
      "346: model.24.m.1.bias\t\ttorch.Size([255])\n",
      "347: model.24.m.2.weight\t\ttorch.Size([255, 512, 1, 1])\n",
      "348: model.24.m.2.bias\t\ttorch.Size([255])\n"
     ]
    }
   ],
   "source": [
    "v5_total_k, v5_total_v = [], []\n",
    "v5_focus_layer = []\n",
    "v5_stage_1_conv = []\n",
    "for i, (k, v) in enumerate(v5_state_dict.items()):\n",
    "    if 'anchor' not in k:\n",
    "        v5_total_k.append(k)\n",
    "        v5_total_v.append(v)\n",
    "        print(f'{i}: {k}\\t\\t{v.shape}')\n",
    "    if \"model.0\" in k:\n",
    "        v5_focus_layer.append(v)\n",
    "    if \"model.1\" in k:\n",
    "        v5_stage_1_conv.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "264fb90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348, 348)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_total_k), len(v5_total_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c593c699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(my_total_k)):\n",
    "    if my_total_v[i].shape != v5_total_v[i].shape:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599fa25f",
   "metadata": {},
   "source": [
    "## load prarmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d677d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 6, 6]) torch.Size([32, 3, 6, 6])\n",
      "torch.Size([64, 32, 3, 3]) torch.Size([64, 32, 3, 3])\n",
      "torch.Size([32, 64, 1, 1]) torch.Size([32, 64, 1, 1])\n",
      "torch.Size([32, 64, 1, 1]) torch.Size([32, 64, 1, 1])\n",
      "torch.Size([64, 64, 1, 1]) torch.Size([64, 64, 1, 1])\n",
      "torch.Size([32, 32, 1, 1]) torch.Size([32, 32, 1, 1])\n",
      "torch.Size([32, 32, 3, 3]) torch.Size([32, 32, 3, 3])\n",
      "torch.Size([128, 64, 3, 3]) torch.Size([128, 64, 3, 3])\n",
      "torch.Size([64, 128, 1, 1]) torch.Size([64, 128, 1, 1])\n",
      "torch.Size([64, 128, 1, 1]) torch.Size([64, 128, 1, 1])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128, 128, 1, 1])\n",
      "torch.Size([64, 64, 1, 1]) torch.Size([64, 64, 1, 1])\n",
      "torch.Size([64, 64, 3, 3]) torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 64, 1, 1]) torch.Size([64, 64, 1, 1])\n",
      "torch.Size([64, 64, 3, 3]) torch.Size([64, 64, 3, 3])\n",
      "torch.Size([256, 128, 3, 3]) torch.Size([256, 128, 3, 3])\n",
      "torch.Size([128, 256, 1, 1]) torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128, 256, 1, 1]) torch.Size([128, 256, 1, 1])\n",
      "torch.Size([256, 256, 1, 1]) torch.Size([256, 256, 1, 1])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 128, 3, 3]) torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 128, 3, 3]) torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 128, 3, 3]) torch.Size([128, 128, 3, 3])\n",
      "torch.Size([512, 256, 3, 3]) torch.Size([512, 256, 3, 3])\n",
      "torch.Size([256, 512, 1, 1]) torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1]) torch.Size([256, 512, 1, 1])\n",
      "torch.Size([512, 512, 1, 1]) torch.Size([512, 512, 1, 1])\n",
      "torch.Size([256, 256, 1, 1]) torch.Size([256, 256, 1, 1])\n",
      "torch.Size([256, 256, 3, 3]) torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 512, 1, 1]) torch.Size([256, 512, 1, 1])\n",
      "torch.Size([512, 1024, 1, 1]) torch.Size([512, 1024, 1, 1])\n",
      "torch.Size([256, 512, 1, 1]) torch.Size([256, 512, 1, 1])\n",
      "torch.Size([128, 512, 1, 1]) torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128, 512, 1, 1]) torch.Size([128, 512, 1, 1])\n",
      "torch.Size([256, 256, 1, 1]) torch.Size([256, 256, 1, 1])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 128, 3, 3]) torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 256, 1, 1]) torch.Size([128, 256, 1, 1])\n",
      "torch.Size([64, 256, 1, 1]) torch.Size([64, 256, 1, 1])\n",
      "torch.Size([64, 256, 1, 1]) torch.Size([64, 256, 1, 1])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128, 128, 1, 1])\n",
      "torch.Size([64, 64, 1, 1]) torch.Size([64, 64, 1, 1])\n",
      "torch.Size([64, 64, 3, 3]) torch.Size([64, 64, 3, 3])\n",
      "torch.Size([128, 128, 3, 3]) torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 256, 1, 1]) torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128, 256, 1, 1]) torch.Size([128, 256, 1, 1])\n",
      "torch.Size([256, 256, 1, 1]) torch.Size([256, 256, 1, 1])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 128, 3, 3]) torch.Size([128, 128, 3, 3])\n",
      "torch.Size([256, 256, 3, 3]) torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 512, 1, 1]) torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1]) torch.Size([256, 512, 1, 1])\n",
      "torch.Size([512, 512, 1, 1]) torch.Size([512, 512, 1, 1])\n",
      "torch.Size([256, 256, 1, 1]) torch.Size([256, 256, 1, 1])\n",
      "torch.Size([256, 256, 3, 3]) torch.Size([256, 256, 3, 3])\n",
      "torch.Size([255, 128, 1, 1]) torch.Size([255, 128, 1, 1])\n",
      "torch.Size([255, 256, 1, 1]) torch.Size([255, 256, 1, 1])\n",
      "torch.Size([255, 512, 1, 1]) torch.Size([255, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "total = v5_total_v[:]\n",
    "for m in yolo.modules():\n",
    "    # if i >= 362:\n",
    "    #     continue\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        m.weight.data = total[i]\n",
    "        print(m.weight.data.shape, total[i].shape)\n",
    "        i += 1\n",
    "        if m.bias is not None:\n",
    "            m.bias.data = total[i]\n",
    "            i += 1\n",
    "        \n",
    "    if isinstance(m, torch.nn.BatchNorm2d):\n",
    "        m.weight.data = total[i]\n",
    "        i += 1\n",
    "        m.bias.data = total[i]\n",
    "        i += 1\n",
    "        m.running_mean = total[i]\n",
    "        i += 1\n",
    "        m.running_var = total[i]\n",
    "        i += 1\n",
    "        m.num_batches_tracked = total[i]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04aa4315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b652d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "total = v5_total_v[:]\n",
    "for m in yolo.modules():\n",
    "    # if i >= 362:\n",
    "    #     continue\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        assert (m.weight.data == total[i]).all()\n",
    "        i += 1\n",
    "        if m.bias is not None:\n",
    "            assert (m.bias.data == total[i]).all()\n",
    "            i += 1\n",
    "    if isinstance(m, torch.nn.BatchNorm2d):\n",
    "        assert (m.weight.data == total[i]).all()\n",
    "        i += 1\n",
    "        assert (m.bias.data == total[i]).all()\n",
    "        i += 1\n",
    "        assert (m.running_mean == total[i]).all()\n",
    "        i += 1\n",
    "        assert (m.running_var == total[i]).all()\n",
    "        i += 1\n",
    "        assert (m.num_batches_tracked == total[i]).all()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0afff0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output_state = yolo.state_dict()\n",
    "torch.save({'model_state_dict': my_output_state}, \"./yolov5s_for_coco.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3392332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
