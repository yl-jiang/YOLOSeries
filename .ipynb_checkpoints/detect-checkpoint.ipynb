{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffad4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import emoji\n",
    "from pathlib import Path\n",
    "import sys\n",
    "current_work_directionary = Path('__file__').parent.absolute()\n",
    "sys.path.insert(0, str(current_work_directionary))\n",
    "\n",
    "import cv2\n",
    "import torch.cuda\n",
    "from models import Yolov5Small, Yolov5SmallWithPlainBscp, Yolov5Large, Yolov5Middle, Yolov5XLarge\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from utils import cv2_save_img\n",
    "from utils import maybe_mkdir, clear_dir\n",
    "from utils import time_synchronize\n",
    "from datetime import datetime\n",
    "import torch.nn.functional as F\n",
    "from trainer.EMA import ExponentialMovingAverage\n",
    "from trainer import Evaluate\n",
    "import time\n",
    "from dataset import testdataloader, cocotestdataloader\n",
    "from utils import mAP, cv2_save_img_plot_pred_gt, ConvBnAct, fuse_conv_bn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85a8b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "\n",
    "    def __init__(self, anchors, nms_hyp, test_hyp):\n",
    "        self.test_hyp = test_hyp\n",
    "        # parameters\n",
    "        self.select_device()\n",
    "        self.use_cuda = self.test_hyp['device'] == 'cuda'\n",
    "        self.anchors = anchors\n",
    "        self.nms_hyp = nms_hyp\n",
    "        if isinstance(anchors, (list, tuple)):\n",
    "            self.anchors = torch.tensor(anchors)  # (3, 3, 2)\n",
    "        self.anchors = self.anchors.to(test_hyp['device'])\n",
    "        anchor_num_per_stage = self.anchors.size(0)  # 3\n",
    "\n",
    "        # 确保输入图片的shape必须能够被32整除（对yolov5s而言），如果不满足条件则对设置的输入shape进行调整\n",
    "        self.test_hyp['input_img_size'] = self.padding(self.test_hyp['input_img_size'], 32)\n",
    "    \n",
    "        # self.testdataloader = testdataloader(self.test_hyp['data_dir'], self.test_hyp['input_img_size'])\n",
    "        self.testdataset, self.testdataloader = cocotestdataloader(self.test_hyp['data_dir'], \n",
    "                                                                   self.test_hyp['set_name'], \n",
    "                                                                   self.test_hyp['use_crowd'], \n",
    "                                                                   self.test_hyp['input_img_size'], \n",
    "                                                                   self.test_hyp['batch_size'], \n",
    "                                                                   self.test_hyp['num_workers'])\n",
    "\n",
    "        if self.test_hyp['current_work_path'] is None:\n",
    "            self.cwd = Path('./').absolute()\n",
    "        else:\n",
    "            self.cwd = Path(self.test_hyp['current_work_path'])\n",
    "\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406]).float()\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225]).float()\n",
    "\n",
    "        # model, optimizer, loss, lr_scheduler, ema\n",
    "        # self.model = Yolov5SmallWithPlainBscp(anchor_num_per_stage, self.test_hyp['num_class']).to(self.test_hyp['device'])\n",
    "        # self.model = Yolov5Small(anchor_num_per_stage, self.test_hyp['num_class']).to(self.test_hyp['device'])\n",
    "        # self.model = Yolov5Middle(anchor_num_per_stage, self.test_hyp['num_class']).to(self.test_hyp['device'])\n",
    "        self.model = Yolov5Large(anchor_num_per_stage, self.test_hyp['num_class']).to(self.test_hyp['device'])\n",
    "#         self.model = Yolov5XLarge(anchor_num_per_stage, self.test_hyp['num_class']).to(self.test_hyp['device'])\n",
    "\n",
    "        self.validate = Evaluate(self.model, self.anchors, self.test_hyp['device'], \n",
    "                                 self.test_hyp['num_class'], self.test_hyp['input_img_size'], \n",
    "                                 self.nms_hyp)\n",
    "        self.ema_model = ExponentialMovingAverage(self.model, 0)\n",
    "\n",
    "        if Path(self.test_hyp[\"pretrained_model_path\"]).exists():\n",
    "            try:\n",
    "                self.load(self.test_hyp['pretrained_model_path'], False, 'cpu')\n",
    "            except Exception as err:\n",
    "                print(err)\n",
    "\n",
    "        model_summary_before_fuse = summary_model(self.model)\n",
    "        print(model_summary_before_fuse)\n",
    "        # ============= to do =====================\n",
    "        self.fuse_conv_bn()\n",
    "        model_summary_after_fuse = summary_model(self.model)\n",
    "        print(model_summary_after_fuse)\n",
    "        # =========================================\n",
    "\n",
    "    def fuse_conv_bn(self):\n",
    "        for m in self.model.modules():\n",
    "            if isinstance(m, ConvBnAct) and hasattr(m, 'bn'):\n",
    "                m.conv = fuse_conv_bn(m.conv, m.bn)\n",
    "                delattr(m, 'bn')\n",
    "                m.forward = m.forward_fuse\n",
    "        \n",
    "    @staticmethod\n",
    "    def padding(hw, factor=32):\n",
    "        h, w = hw\n",
    "        h_mod = h % factor\n",
    "        w_mod = w % factor\n",
    "        if h_mod > 0:\n",
    "            h = (h // factor + 1) * factor\n",
    "        if w_mod > 0:\n",
    "            w = (w // factor + 1) * factor\n",
    "        return h, w\n",
    "\n",
    "    def preds_postprocess(self, inp, outputs, info):\n",
    "        \"\"\"\n",
    "\n",
    "        :param inp: normalization image\n",
    "        :param outputs:\n",
    "        :param info:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        processed_preds = []\n",
    "        processed_inp = []\n",
    "        for i in range(len(outputs)):\n",
    "            scale, pad_top, pad_left = info[i]['scale'], info[i]['pad_top'], info[i]['pad_left']\n",
    "            pad_bot, pad_right = info[i]['pad_bottom'], info[i]['pad_right']\n",
    "            pred = outputs[i]\n",
    "            org_h, org_w = info[i]['org_shape']\n",
    "            cur_h, cur_w = inp[i].size(1), inp[i].size(2)\n",
    "\n",
    "            img = inp[i].permute(1, 2, 0)\n",
    "            img = (img * self.std + self.mean) * 255.\n",
    "            img = img.numpy().astype(np.uint8)\n",
    "            img = img[pad_top:(cur_h - pad_bot), pad_left:(cur_w - pad_right), :]\n",
    "            img = cv2.resize(img, (org_w, org_h), interpolation=0)\n",
    "\n",
    "            if pred is not None and pred.size(0) > 0:\n",
    "                pred[:, [0, 2]] -= pad_left\n",
    "                pred[:, [1, 3]] -= pad_top\n",
    "                pred[:, [0, 1, 2, 3]] /= scale\n",
    "                pred[:, [0, 2]] = pred[:, [0, 2]].clamp(1, org_w - 1)\n",
    "                pred[:, [1, 3]] = pred[:, [1, 3]].clamp(1, org_h - 1)\n",
    "                if self.test_hyp['use_auxiliary_classifier']:\n",
    "                    # 将每个预测框中的物体抠出来，放到一个额外的分类器再进行预测一次是否存在对象\n",
    "                    pass\n",
    "                processed_preds.append(pred.cpu().numpy())\n",
    "            else:\n",
    "                processed_preds.append(np.ones((1, 6)) * -1.)\n",
    "            processed_inp.append(img)\n",
    "        return processed_inp, processed_preds\n",
    "\n",
    "    def select_device(self):\n",
    "        if self.test_hyp['device'].lower() != 'cpu':\n",
    "            if torch.cuda.is_available():\n",
    "                self.test_hyp['device'] = 'cuda'\n",
    "            else:\n",
    "                self.test_hyp['device'] = 'cpu'\n",
    "\n",
    "    def load(self, model_path, load_optimizer, map_location):\n",
    "        assert Path(model_path).exists(), f\"model path is not exist {model_path}\"\n",
    "        state_dict = torch.load(model_path, map_location=map_location)\n",
    "        if \"model\" not in state_dict:\n",
    "            print(\"not found model_state_dict in this state_dict, load model failed!\")\n",
    "        else:\n",
    "            print(f\"use pretrained model {model_path}\")\n",
    "            self.model.load_state_dict(state_dict[\"model\"])\n",
    "        if load_optimizer and \"optim\" in state_dict:\n",
    "            print(f\"use pretrained optimizer {model_path}\")\n",
    "            self.optimizer.load_state_dict(state_dict['optim'])\n",
    "        del state_dict\n",
    "    \n",
    "    def gt_bbox_postprocess(self, anns, infoes):\n",
    "        \"\"\"\n",
    "        testdataloader出来的gt bboxes经过了letter resize，这里将其还原到原始的bboxes\n",
    "\n",
    "        :param: anns: dict\n",
    "        \"\"\"\n",
    "        ppb = []  # post processed bboxes\n",
    "        ppc = []  # post processed classes\n",
    "        for i in range(anns.shape[0]):\n",
    "            scale, pad_top, pad_left = infoes[i]['scale'], infoes[i]['pad_top'], infoes[i]['pad_left']\n",
    "            valid_idx = anns[i][:, 4] >= 0\n",
    "            ann_valid = anns[i][valid_idx]\n",
    "            ann_valid[:, [0, 2]] -= pad_left\n",
    "            ann_valid[:, [1, 3]] -= pad_top\n",
    "            ann_valid[:, :4] /= scale\n",
    "            ppb.append(ann_valid[:, :4].cpu().numpy())\n",
    "            ppc.append(ann_valid[:, 4].cpu().numpy().astype('uint16'))\n",
    "        return ppb, ppc\n",
    "\n",
    "    def predtict_all(self):\n",
    "        \"\"\"\n",
    "        测试testdataloader中的所有图片并将结果保存到磁盘\n",
    "        \"\"\"\n",
    "        for i, x in enumerate(self.testdataloader):\n",
    "            imgs = x['imgs']  # (bn, 3, h, w)\n",
    "            infoes = x['resize_infoes']\n",
    "            gt_bbox, gt_cls = self.gt_bbox_postprocess(x['anns'], infoes)\n",
    "            outputs = self.validate(imgs.to(self.test_hyp['device']), self.test_hyp['use_tta'], self.nms_hyp['wfb'])\n",
    "            imgs, preds = self.preds_postprocess(imgs.cpu(), outputs, infoes)\n",
    "            pred_cls = [preds[j][:, 5] for j in range(len(imgs))]\n",
    "\n",
    "            if self.test_hyp['save_img']:\n",
    "                for k in range(len(imgs)):\n",
    "                    save_path = str(self.cwd / 'result' / 'tmp' / f\"{i * self.test_hyp['batch_size'] + k} {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.png\")\n",
    "                    maybe_mkdir(Path(save_path).parent)\n",
    "                    pred_lab = [self.testdataset.class2label[int(c)] for c in pred_cls[k]]\n",
    "                    gt_lab = [self.testdataset.class2label[int(c)] for c in gt_cls[k]]\n",
    "                    if self.test_hyp['show_gt_bbox']:\n",
    "                        cv2_save_img_plot_pred_gt(imgs[k], preds[k][:, :4], pred_lab, preds[k][:, 4], gt_bbox[k], gt_lab, save_path)\n",
    "                    else:\n",
    "                        cv2_save_img(imgs[k], preds[k][:, :4], pred_lab, preds[k][:, 4], save_path)\n",
    "            del imgs, preds\n",
    "\n",
    "    def count_object(self, pred_lab):\n",
    "        \"\"\"\n",
    "        按照object的个数升序输出。\n",
    "\n",
    "        :param pred_lab: [(X, ), (Y, ), (Z, ), ...]\n",
    "        \"\"\"\n",
    "        msg = []\n",
    "        for lab in pred_lab:\n",
    "            counter = Counter(lab)\n",
    "            names, numbers = [], []\n",
    "            for nam, num in counter.items():\n",
    "                names.append(nam)\n",
    "                numbers.append(str(num))\n",
    "            sort_index = np.argsort([int(i) for i in numbers])\n",
    "            ascending_numbers = [numbers[i] for i in sort_index]\n",
    "            ascending_names = [names[i] for i in sort_index]\n",
    "            if len(numbers) > 0:\n",
    "                if (self.cwd / \"result\" / 'pkl' / \"coco_emoji_names.pkl\").exists():\n",
    "                    coco_emoji = pickle.load(open(str(self.cwd / \"result\" / 'pkl' / \"coco_emoji_names.pkl\"), 'rb'))\n",
    "                    msg_ls = [\" \".join([number, coco_emoji[name]]) for name, number in zip(ascending_names, ascending_numbers)]\n",
    "                else:\n",
    "                    msg_ls = [\" \".join([number, name]) for name, number in zip(ascending_names, ascending_numbers)]\n",
    "            else:\n",
    "                msg_ls = [\"No object has been found!\"]\n",
    "            msg.append(emoji.emojize(\"; \".join(msg_ls)))\n",
    "        return msg\n",
    "\n",
    "    def calculate_mAP(self):\n",
    "        \"\"\"\n",
    "        计算testdataloader中所有数据的map\n",
    "        \"\"\"\n",
    "        start_t = time_synchronize()\n",
    "        pred_bboxes, pred_classes, pred_confidences, pred_labels, gt_bboxes = [], [], [], [], []\n",
    "        for i, x in enumerate(self.testdataloader):\n",
    "\n",
    "            imgs = x['imgs']  # (bn, 3, h, w)\n",
    "            infoes = x['resize_infoes']\n",
    "\n",
    "            # gt_bbox: [(M, 4), (N, 4), (P, 4), ...]; gt_cls: [(M,), (N, ), (P, ), ...]\n",
    "            # coco val2017 dataset中存在有些图片没有对应的gt bboxes的情况\n",
    "            gt_bbox, gt_cls = self.gt_bbox_postprocess(x['anns'], infoes)\n",
    "            gt_bboxes.extend(gt_bbox)\n",
    "\n",
    "            # 统计预测一个batch需要花费的时间\n",
    "            t1 = time_synchronize()\n",
    "            outputs = self.validate(imgs.to(self.test_hyp['device']), self.test_hyp['use_tta'], self.nms_hyp['wfb'])\n",
    "            # preds: [(X, 6), (Y, 6), (Z, 6), ...]\n",
    "            imgs, preds = self.preds_postprocess(imgs.cpu(), outputs, infoes)\n",
    "            t = time_synchronize() - t1\n",
    "\n",
    "            batch_pred_box, batch_pred_cof, batch_pred_cls, batch_pred_lab = [], [], [], []\n",
    "            for j in range(len(imgs)):\n",
    "                valid_idx = preds[j][:, 5] >= 0\n",
    "                if valid_idx.sum() == 0:\n",
    "                    pred_box, pred_cls, pred_cof, pred_lab = [], [], [], []\n",
    "                else:\n",
    "                    pred_box = preds[j][valid_idx, :4]\n",
    "                    pred_cof = preds[j][valid_idx, 4]\n",
    "                    pred_cls = preds[j][valid_idx, 5]\n",
    "                    pred_lab = [self.testdataset.class2label[int(c)] for c in pred_cls] \n",
    "\n",
    "                batch_pred_box.append(pred_box)\n",
    "                batch_pred_cls.append(pred_cls)\n",
    "                batch_pred_cof.append(pred_cof)\n",
    "                batch_pred_lab.append(pred_lab)\n",
    "\n",
    "            pred_bboxes.extend(batch_pred_box)\n",
    "            pred_classes.extend(batch_pred_cls)\n",
    "            pred_confidences.extend(batch_pred_cof)\n",
    "            pred_labels.extend(batch_pred_lab)\n",
    "            \n",
    "            obj_msg = self.count_object(batch_pred_lab)\n",
    "            \n",
    "            for k in range(len(imgs)):\n",
    "                count = i * self.test_hyp['batch_size'] + k\n",
    "                print(f\"[{count:>05}/{len(self.testdataset)}] ➡️ \" + obj_msg[k] + f\" ({(t/len(imgs)):.2f}s)\")\n",
    "                if self.test_hyp['save_img']:\n",
    "                    save_path = str(self.cwd / 'result' / 'tmp' / f\"{i * self.test_hyp['batch_size'] + k} {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.png\")\n",
    "                    if self.test_hyp['show_gt_bbox']:\n",
    "                        gt_lab = [self.testdataset.class2label[int(c)] for c in gt_cls[k]]\n",
    "                        cv2_save_img_plot_pred_gt(imgs[k], batch_pred_box[k], batch_pred_lab[k], batch_pred_cof[k], gt_bbox[k], gt_lab, save_path)\n",
    "                    else:\n",
    "                        cv2_save_img(imgs[k], batch_pred_box[k], batch_pred_lab[k], batch_pred_cof[k], save_path)\n",
    "            del imgs, preds\n",
    "\n",
    "        total_use_time = time_synchronize() - start_t\n",
    "\n",
    "        all_preds = []\n",
    "        for pred_box, pred_cof in zip(pred_bboxes, pred_confidences):\n",
    "            if len(pred_box) == 0:\n",
    "                all_preds.append([])\n",
    "            else:\n",
    "                all_preds.append(np.concatenate((pred_box, pred_cof[:, None]), axis=1))\n",
    "\n",
    "        # 如果测试的数据较多，计算一次mAP需花费较多时间，将结果保存下来以方便后续统计\n",
    "        if self.test_hyp['save_pred_bbox']:\n",
    "            pickle.dump(all_preds, open(self.cwd / \"result\" / \"pkl\" / \"pred_bbox_1024_tta.pkl\", 'wb'))\n",
    "            pickle.dump(gt_bboxes, open(self.cwd / \"result\" / \"pkl\" / \"gt_bbox.pkl\", \"wb\"))\n",
    "\n",
    "        map = mAP(all_preds, gt_bboxes, 0.5)\n",
    "        print(f\"use time: {total_use_time:.2f}s\")\n",
    "        print('AP: %.2f %%' % (map.elevenPointAP * 100))\n",
    "        print('mAP: %.2f %%' % (map.everyPointAP * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a11bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.61s)\n",
      "creating index...\n",
      "index created!\n",
      "use pretrained model ./checkpoints/every_for_coco_large.pth\n",
      "[00000/5000] ➡️ 1 🪴; 1 :sink:; 1 :dining_table:; 1 🔪; 2 🧑; 2 :oven:; 2 🥄; 4 🍚; 4 🥤 (1.81s)\n",
      "[00001/5000] ➡️ 1 :oven:; 1 :dining_table:; 1 🪑; 1 🪴; 1 🍌; 1 🍚; 2 :refrigerator:; 6 🍊 (1.81s)\n",
      "[00002/5000] ➡️ 1 ☂; 1 💼; 1 🚚; 1 🚗; 1 🎒; 1 🛹; 2 🚦; 5 🧑 (1.81s)\n",
      "[00003/5000] ➡️ 1 🚲; 1 📺; 1 :bench:; 2 🛹; 19 🧑 (1.81s)\n",
      "[00004/5000] ➡️ 1 🚲; 6 🚗 (1.81s)\n",
      "[00005/5000] ➡️ 1 🚽; 1 🥤; 2 :sink: (1.81s)\n",
      "[00006/5000] ➡️ 1 :sink:; 1 🚽 (1.81s)\n",
      "[00007/5000] ➡️ 3 🏍; 7 🧑 (1.81s)\n",
      "[00008/5000] ➡️ 1 📚; 2 🔪; 7 🚽 (1.78s)\n",
      "[00009/5000] ➡️ 1 :sink:; 2 🚽 (1.78s)\n",
      "[00010/5000] ➡️ 1 ☂; 1 🚲; 2 🏍; 4 🚗; 13 🧑 (1.78s)\n",
      "[00011/5000] ➡️ 1 🧑; 1 📺; 1 💻; 1 ⌨; 1 🥤; 26 📚 (1.78s)\n",
      "[00012/5000] ➡️ 2 🪴; 2 🏺 (1.78s)\n",
      "[00013/5000] ➡️ 1 🛏; 1 🧑; 1 🛋; 2 📺; 20 📚 (1.78s)\n",
      "[00014/5000] ➡️ 1 🍚; 1 🏺; 4 🍊 (1.78s)\n",
      "[00015/5000] ➡️ 1 💼; 1 🛥; 2 🧑; 2 ✈ (1.78s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20431/304517056.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m61\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m62\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m59\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m119\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m116\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m156\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m198\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m373\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m326\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms_hyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_hyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_mAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_20431/3723890364.py\u001b[0m in \u001b[0;36mcalculate_mAP\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# 统计预测一个batch需要花费的时间\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_synchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_hyp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_hyp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_tta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms_hyp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wfb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0;31m# preds: [(X, 6), (Y, 6), (Z, 6), ...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds_postprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfoes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JYL/Programs/Yolov5mBase/trainer/eval.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, use_tta, use_wfb)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_tta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mmerge_preds_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minpendent_preds_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_time_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, N, 85)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_wfb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_wfb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpendent_preds_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JYL/Programs/Yolov5mBase/trainer/eval.py\u001b[0m in \u001b[0;36mtest_time_augmentation\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# (bs, M, 85)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mripe_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mripe_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# flip axis y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JYL/Programs/Yolov5mBase/trainer/eval.py\u001b[0m in \u001b[0;36mdo_inference\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mpreds_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0minput_img_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_img_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mstage_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# [(5, 255, h/8, w/8), (5, 255, h/16, w/16), (5, 255, h/32, w/32)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JYL/Programs/Yolov5mBase/models/yolov5l.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_stage3_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_x\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bn, 128, 40, 40)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead2_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bn, 256, 40, 40)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mmid_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_stage3_bscp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bn, 256, 40, 40)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_stage4_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid_x\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bn, 256, 20, 20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead1_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bn, 512, 20, 20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JYL/Programs/Yolov5mBase/utils/layer_tools.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcba1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcba2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcba3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JYL/Programs/Yolov5mBase/utils/layer_tools.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_bn_act_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_bn_act_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JYL/Programs/Yolov5mBase/utils/layer_tools.py\u001b[0m in \u001b[0;36mforward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_fuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    nms_hyp = {\n",
    "        'iou_threshold': 0.45,  # 最后使用iou threshold过滤掉一批预测框\n",
    "        'conf_threshold': 0.25,  # 先使用conf threshold过滤掉一批预测框\n",
    "        \"cls_threshold\": 0.3,  # 再使用cls threshold过滤掉一批预测框\n",
    "        \"max_predictions_per_img\": 300,\n",
    "        \"min_prediction_box_wh\": 2,\n",
    "        \"max_prediction_box_wh\": 4096,\n",
    "        \"iou_type\": 'iou',\n",
    "        'mutil_label': False,  # 一个object是否可以分配多个标签\n",
    "        \"agnostic\": True,  # 是否只在同一个类别的bbox间进行NMS\n",
    "        \"postprocess_bbox\": False,  # 是否对预测的bbox进一步调优\n",
    "        \"wfb\": False,  # use NMS or Weighted Fusion Bbox\n",
    "        \"wfb_weights\": [1, 1, 1],\n",
    "        \"wfb_iou_threshold\": 0.5,\n",
    "        \"wfb_skip_box_threshold\": 0.001\n",
    "    }\n",
    "\n",
    "    test_hyp = {\n",
    "        \"data_dir\": \"/home/uih/JYL/Dataset/COCO2017/\", \n",
    "        # \"data_dir\": \"./result/coco_test_imgs\", \n",
    "        \"set_name\": \"val2017\",\n",
    "        'use_auxiliary_classifier': False,\n",
    "        'batch_size': 8,\n",
    "        \"input_img_size\": [640, 640],\n",
    "        \"num_workers\": 6,\n",
    "        \"save_img\": True,\n",
    "        \"device\": 'cpu', \n",
    "        \"use_tta\": True, \n",
    "        \"use_crowd\": False, \n",
    "        \"save_pred_bbox\": True,\n",
    "        \"current_work_path\": None, \n",
    "        \"use_pretrained_mdoel\": True, \n",
    "        \"pretrained_model_path\": \"./checkpoints/every_for_coco_large.pth\",\n",
    "        \"num_class\": 80,\n",
    "        \"show_gt_bbox\": True, \n",
    "    }\n",
    "\n",
    "    anchors = torch.tensor([[[10, 13], [16, 30], [33, 23]], [[30, 61], [62, 45], [59, 119]], [[116, 90], [156, 198], [373, 326]]])\n",
    "    train = Training(anchors, nms_hyp, test_hyp)\n",
    "    train.calculate_mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72567ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
