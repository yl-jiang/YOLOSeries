{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "current_work_directionary = Path('__file__').absolute().parent\n",
    "sys.path.insert(0, str(current_work_directionary))\n",
    "\n",
    "from dataset import build_dataloader, build_test_dataloader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_hyp = {\n",
    "            'data_aug_prespective_p': 1.0,\n",
    "            'data_aug_scale': 0.,\n",
    "            'data_aug_shear': 0,\n",
    "            'data_aug_translate': 0.5,\n",
    "            'data_aug_degree': 0,\n",
    "            'data_aug_prespective': 1.0,\n",
    "            'data_aug_hsv_p': 1,\n",
    "            \"data_aug_hsv_hgain\": 0.015,\n",
    "            \"data_aug_hsv_sgain\": 0.7,\n",
    "            \"data_aug_hsv_vgain\": 0.4,\n",
    "            'data_aug_mixup_p': 0.0,\n",
    "            'data_aug_fliplr_p': 0,\n",
    "            'data_aug_flipud_p': 0,\n",
    "            'data_aug_fill_value': 128,\n",
    "            'data_aug_mosaic_p': 1., \n",
    "            \"data_aug_cutout_p\": 1.0, \n",
    "            \"data_aug_cutout_iou_thr\": 0.2, \n",
    "            \"data_aug_scale_jitting_p\": 0.1, \n",
    "            'input_img_size': 448,\n",
    "}\n",
    "\n",
    "img_dir = '../../Dataset/COCO/val/img'\n",
    "lab_dir = \"../../Dataset/COCO/val/lab\"\n",
    "name_path = '../../Dataset/COCO/val/names.txt'\n",
    "input_dim = [448, 448]\n",
    "cache_num = 20\n",
    "enable_data_aug = True\n",
    "seed = 7\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "pin_memory = True\n",
    "shuffle = True\n",
    "drop_last = False\n",
    "\n",
    "\n",
    "dataset, dataloader, prefetcher = build_dataloader(img_dir, lab_dir, name_path, input_dim, aug_hyp, cache_num, \n",
    "                                                    enable_data_aug, seed, batch_size, num_workers, pin_memory, shuffle, drop_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = np.random.randint(0, len(dataset))\n",
    "x = dataset.pull_item(img_id)\n",
    "ann = x[1]\n",
    "img = x[0]\n",
    "# img = img.permute(1, 2, 0)\n",
    "# img = np.clip(img * 255.0, 0.0, 255.0)\n",
    "img_mdy = np.ascontiguousarray(img.astype('uint8'))\n",
    "h, w, _ = img.shape\n",
    "save_path = current_work_directionary / \"result\" / \"tmp\" / f\"batch_img_id_{img_id}.png\"\n",
    "dataset.cv2_save_fig(img_mdy, ann['bboxes'], ann['classes'], str(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏            | 8/625 [00:07<10:07,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(dataloader), ncols=50) as t:\n",
    "    for b, x in enumerate(dataloader):\n",
    "        if b == 2:\n",
    "            dataloader.close_data_aug()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            ann = x['ann'][i]\n",
    "            title = x['img_id'][i]\n",
    "            img = x['img'][i]\n",
    "            img = img.permute(1, 2, 0)\n",
    "            img = np.clip(img * 255.0, 0.0, 255.0)\n",
    "            img_mdy = np.ascontiguousarray(img.numpy().astype('uint8'))\n",
    "            h, w, _ = img.shape\n",
    "            # 该笔数据中是否有object，ann[:, 4] == -1表示没有object\n",
    "            valid_index = torch.nonzero(ann[:, 4] >= 0, as_tuple=False).squeeze(dim=1)\n",
    "            # 如果该笔数据有object的话，就plot出来\n",
    "            if valid_index.numel() > 0:\n",
    "                ann_mdy = {'bboxes': ann[valid_index][:, :4].numpy(),\n",
    "                            'classes': ann[valid_index][:, 4].numpy().astype('uint8')}\n",
    "            # 如果该笔数据中没有发现object，则打印出图片的路径\n",
    "            else:\n",
    "                ann_mdy = {'bboxes': [], 'classes': []}\n",
    "            save_path = current_work_directionary / \"result\" / \"tmp\" / f\"batch_{b}_idx_{i}.png\"\n",
    "            dataset.cv2_save_fig(img_mdy, ann_mdy['bboxes'], ann_mdy['classes'], str(save_path))\n",
    "            # print(f\"{b*batch_size+i}\\t{len(ann_mdy['bboxes'])}\")\n",
    "        \n",
    "        if b >= 3:\n",
    "            break\n",
    "    t.update(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"./result/coco_test_imgs\"\n",
    "dataset, dataloader, prefetcher = build_test_dataloader(datadir, img_size=640, batch_size=2, num_workers=0)\n",
    "\n",
    "with tqdm(total=len(dataloader), ncols=50) as t:\n",
    "    for b, x in enumerate(dataloader):\n",
    "        for i in range(len(x)):\n",
    "            info = x['resize_info'][i]\n",
    "            img = x['img'][i]\n",
    "            img = img.permute(1, 2, 0)\n",
    "            img = np.clip(img * 255.0, 0.0, 255.0)\n",
    "            img_mdy = np.ascontiguousarray(img.numpy().astype('uint8'))\n",
    "            h, w, _ = img.shape\n",
    "            fig = plt.figure(figsize=[8, 8])\n",
    "            plt.imshow(img_mdy)\n",
    "            plt.show()\n",
    "    t.update(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import sys\n",
    "# current_work_directionary = Path('__file__').absolute().parent\n",
    "# sys.path.insert(0, str(current_work_directionary))\n",
    "# import torch\n",
    "# from models import YOLOV8\n",
    "# yolo = YOLOV8(3, 80)\n",
    "# dummy_img = torch.rand(5, 3, 640, 640)\n",
    "# out = yolo(dummy_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(3, 8, 3)\n",
    "b = torch.rand(3, 4, 2)\n",
    "torch.minimum(a[:, :, 1:2], b[:, :, 0][:, None, :]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 8, 1]), torch.Size([3, 1, 4]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, :, 1:2].shape, b[:, :, 0][:, None, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (8) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m8\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m torch\u001b[39m.\u001b[39;49mminimum(a[:, :, \u001b[39m1\u001b[39;49m:\u001b[39m2\u001b[39;49m], b[:, :])\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (8) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "a = torch.rand(8, 3, 3)\n",
    "b = torch.rand(8, 8)\n",
    "torch.minimum(a[:, :, 1:2], b[:, :]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 3, 1]), torch.Size([8, 8]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, :, 1:2].shape, b[:, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6041, 0.1582, 0.2063],\n",
      "         [0.2212, 0.1445, 0.9594],\n",
      "         [0.6227, 0.3079, 0.8007]],\n",
      "\n",
      "        [[0.0452, 0.2405, 0.3296],\n",
      "         [0.2596, 0.3043, 0.1322],\n",
      "         [0.3512, 0.8063, 0.6920]]])\n",
      "tensor([[[1., 1., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 1.],\n",
      "         [1., 1., 0.],\n",
      "         [1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "dim1, dim2, dim3 = 2, 3, 3\n",
    "topk = 2\n",
    "\n",
    "b= torch.rand(dim1, dim2, dim3)\n",
    "print(b)\n",
    "\n",
    "maxv, idx = b.topk(topk, dim=1)\n",
    "shift_dim1 = torch.arange(0, dim1)\n",
    "shift_dim2 = torch.arange(0, topk)\n",
    "shift_dim3 = torch.arange(0, dim3) \n",
    "z, y, x = torch.meshgrid((shift_dim1, shift_dim2, shift_dim3), indexing='ij')\n",
    "# # mesh_grid: (col_num, row_num, 2) -> (row_num, col_num, 2)\n",
    "grid = torch.stack((z, y, x), dim=-1)\n",
    "\n",
    "\n",
    "zs = grid[..., 0]\n",
    "xs = grid[..., 2]\n",
    "\n",
    "c = torch.zeros_like(b)\n",
    "c[zs.flatten(), idx.flatten(), xs.flatten()] = 1\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a00c0a220c6a4fa84f8be1eccff78cca396213150bbb3b308447c2ee397323f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
