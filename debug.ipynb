{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uih/miniconda3/envs/torch1.13/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "current_work_directionary = Path('__file__').absolute().parent\n",
    "sys.path.insert(0, str(current_work_directionary))\n",
    "\n",
    "from dataset import build_dataloader, build_test_dataloader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the consistency of dataset!\n",
      "- Use time 2.079s\n",
      "Parser names!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 11:03:13.990 | WARNING  | dataset.datasets:_cache_image:224 - \n",
      "********************************************************************************\n",
      "You are using cached images in RAM to accelerate training.\n",
      "This requires large system RAM.\n",
      "20(0.40%) images will be cached, there are 5000 images totaly.\n",
      "********************************************************************************\n",
      "\n",
      "2023-01-27 11:03:13.990 | WARNING  | dataset.datasets:_cache_image:255 - You are using cached imgs! Make sure your dataset is not changed!!\n",
      "Everytime the self.input_size is changed in your exp file, you need to delete\n",
      "the cached data and re-generate them.\n",
      "\n",
      "2023-01-27 11:03:13.991 | INFO     | dataset.datasets:_cache_image:261 - Loading cached imgs ...\n",
      "2023-01-27 11:03:13.991 | INFO     | dataset.datasets:_cache_image:262 - cache_file: ../../Dataset/COCO/val/img_img_resized_cache_h448_w448.array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Use time 0.179s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m shuffle \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     34\u001b[0m drop_last \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m dataset, dataloader, prefetcher \u001b[39m=\u001b[39m build_dataloader(img_dir, lab_dir, name_path, input_dim, aug_hyp, cache_num, \n\u001b[1;32m     38\u001b[0m                                                     enable_data_aug, seed, batch_size, num_workers, pin_memory, shuffle, drop_last)\n",
      "File \u001b[0;32m~/JYL/GitHub/YOLOSeries/dataset/data_loader.py:81\u001b[0m, in \u001b[0;36mbuild_dataloader\u001b[0;34m(img_dir, lab_dir, name_path, input_dim, aug_hyp, cache_num, enable_data_aug, seed, batch_size, num_workers, pin_memory, shuffle, drop_last)\u001b[0m\n\u001b[1;32m     79\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataloader_kwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m---> 81\u001b[0m     prefetcher \u001b[39m=\u001b[39m DataPrefetcher(dataloader)\n\u001b[1;32m     82\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     prefetcher \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/JYL/GitHub/YOLOSeries/dataset/data_prefetcher.py:16\u001b[0m, in \u001b[0;36mDataPrefetcher.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, loader):\n\u001b[1;32m     15\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(loader)\n\u001b[0;32m---> 16\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mStream()\n\u001b[1;32m     17\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_cuda \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_cuda_for_image\n\u001b[1;32m     18\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord_stream \u001b[39m=\u001b[39m DataPrefetcher\u001b[39m.\u001b[39m_record_stream_for_image\n",
      "File \u001b[0;32m~/miniconda3/envs/torch1.13/lib/python3.8/site-packages/torch/cuda/streams.py:34\u001b[0m, in \u001b[0;36mStream.__new__\u001b[0;34m(cls, device, priority, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, priority\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     32\u001b[0m     \u001b[39m# setting device manager is expensive, so we avoid it unless necessary\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_cdata\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m---> 34\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Stream, \u001b[39mcls\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__new__\u001b[39;49m(\u001b[39mcls\u001b[39;49m, priority\u001b[39m=\u001b[39;49mpriority, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "aug_hyp = {\n",
    "            'data_aug_prespective_p': 1.0,\n",
    "            'data_aug_scale': 0.,\n",
    "            'data_aug_shear': 0,\n",
    "            'data_aug_translate': 0.5,\n",
    "            'data_aug_degree': 0,\n",
    "            'data_aug_prespective': 1.0,\n",
    "            'data_aug_hsv_p': 1,\n",
    "            \"data_aug_hsv_hgain\": 0.015,\n",
    "            \"data_aug_hsv_sgain\": 0.7,\n",
    "            \"data_aug_hsv_vgain\": 0.4,\n",
    "            'data_aug_mixup_p': 0.0,\n",
    "            'data_aug_fliplr_p': 0,\n",
    "            'data_aug_flipud_p': 0,\n",
    "            'data_aug_fill_value': 128,\n",
    "            'data_aug_mosaic_p': 1., \n",
    "            \"data_aug_cutout_p\": 1.0, \n",
    "            \"data_aug_cutout_iou_thr\": 0.2, \n",
    "            \"data_aug_scale_jitting_p\": 0.1, \n",
    "            'input_img_size': 448,\n",
    "}\n",
    "\n",
    "img_dir = '../../Dataset/COCO/val/img'\n",
    "lab_dir = \"../../Dataset/COCO/val/lab\"\n",
    "name_path = '../../Dataset/COCO/val/names.txt'\n",
    "input_dim = [448, 448]\n",
    "cache_num = 20\n",
    "enable_data_aug = True\n",
    "seed = 7\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "pin_memory = True\n",
    "shuffle = True\n",
    "drop_last = False\n",
    "\n",
    "\n",
    "dataset, dataloader, prefetcher = build_dataloader(img_dir, lab_dir, name_path, input_dim, aug_hyp, cache_num, \n",
    "                                                    enable_data_aug, seed, batch_size, num_workers, pin_memory, shuffle, drop_last)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = np.random.randint(0, len(dataset))\n",
    "x = dataset.pull_item(img_id)\n",
    "ann = x[1]\n",
    "img = x[0]\n",
    "# img = img.permute(1, 2, 0)\n",
    "# img = np.clip(img * 255.0, 0.0, 255.0)\n",
    "img_mdy = np.ascontiguousarray(img.astype('uint8'))\n",
    "h, w, _ = img.shape\n",
    "save_path = current_work_directionary / \"result\" / \"tmp\" / f\"batch_img_id_{img_id}.png\"\n",
    "dataset.cv2_save_fig(img_mdy, ann['bboxes'], ann['classes'], str(save_path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè            | 8/625 [00:07<10:07,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(dataloader), ncols=50) as t:\n",
    "    for b, x in enumerate(dataloader):\n",
    "        if b == 2:\n",
    "            dataloader.close_data_aug()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            ann = x['ann'][i]\n",
    "            title = x['img_id'][i]\n",
    "            img = x['img'][i]\n",
    "            img = img.permute(1, 2, 0)\n",
    "            img = np.clip(img * 255.0, 0.0, 255.0)\n",
    "            img_mdy = np.ascontiguousarray(img.numpy().astype('uint8'))\n",
    "            h, w, _ = img.shape\n",
    "            # ËØ•Á¨îÊï∞ÊçÆ‰∏≠ÊòØÂê¶ÊúâobjectÔºåann[:, 4] == -1Ë°®Á§∫Ê≤°Êúâobject\n",
    "            valid_index = torch.nonzero(ann[:, 4] >= 0, as_tuple=False).squeeze(dim=1)\n",
    "            # Â¶ÇÊûúËØ•Á¨îÊï∞ÊçÆÊúâobjectÁöÑËØùÔºåÂ∞±plotÂá∫Êù•\n",
    "            if valid_index.numel() > 0:\n",
    "                ann_mdy = {'bboxes': ann[valid_index][:, :4].numpy(),\n",
    "                            'classes': ann[valid_index][:, 4].numpy().astype('uint8')}\n",
    "            # Â¶ÇÊûúËØ•Á¨îÊï∞ÊçÆ‰∏≠Ê≤°ÊúâÂèëÁé∞objectÔºåÂàôÊâìÂç∞Âá∫ÂõæÁâáÁöÑË∑ØÂæÑ\n",
    "            else:\n",
    "                ann_mdy = {'bboxes': [], 'classes': []}\n",
    "            save_path = current_work_directionary / \"result\" / \"tmp\" / f\"batch_{b}_idx_{i}.png\"\n",
    "            dataset.cv2_save_fig(img_mdy, ann_mdy['bboxes'], ann_mdy['classes'], str(save_path))\n",
    "            # print(f\"{b*batch_size+i}\\t{len(ann_mdy['bboxes'])}\")\n",
    "        \n",
    "        if b >= 3:\n",
    "            break\n",
    "    t.update(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"./result/coco_test_imgs\"\n",
    "dataset, dataloader, prefetcher = build_test_dataloader(datadir, img_size=640, batch_size=2, num_workers=0)\n",
    "\n",
    "with tqdm(total=len(dataloader), ncols=50) as t:\n",
    "    for b, x in enumerate(dataloader):\n",
    "        for i in range(len(x)):\n",
    "            info = x['resize_info'][i]\n",
    "            img = x['img'][i]\n",
    "            img = img.permute(1, 2, 0)\n",
    "            img = np.clip(img * 255.0, 0.0, 255.0)\n",
    "            img_mdy = np.ascontiguousarray(img.numpy().astype('uint8'))\n",
    "            h, w, _ = img.shape\n",
    "            fig = plt.figure(figsize=[8, 8])\n",
    "            plt.imshow(img_mdy)\n",
    "            plt.show()\n",
    "    t.update(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a00c0a220c6a4fa84f8be1eccff78cca396213150bbb3b308447c2ee397323f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
