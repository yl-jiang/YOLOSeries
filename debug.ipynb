{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "current_work_directionary = Path('__file__').absolute().parent\n",
    "sys.path.insert(0, str(current_work_directionary))\n",
    "\n",
    "from dataset import build_dataloader, build_test_dataloader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 15:30:58.929 | WARNING  | dataset.datasets:_cache_image:224 - \n",
      "********************************************************************************\n",
      "You are using cached images in RAM to accelerate training.\n",
      "This requires large system RAM.\n",
      "20(0.40%) images will be cached, there are 5000 images totaly.\n",
      "********************************************************************************\n",
      "\n",
      "2023-01-25 15:30:58.930 | WARNING  | dataset.datasets:_cache_image:255 - You are using cached imgs! Make sure your dataset is not changed!!\n",
      "Everytime the self.input_size is changed in your exp file, you need to delete\n",
      "the cached data and re-generate them.\n",
      "\n",
      "2023-01-25 15:30:58.930 | INFO     | dataset.datasets:_cache_image:261 - Loading cached imgs ...\n",
      "2023-01-25 15:30:58.930 | INFO     | dataset.datasets:_cache_image:262 - cache_file: ../../Dataset/COCO/val/img_img_resized_cache_h448_w448.array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the consistency of dataset!\n",
      "- Use time 0.053s\n",
      "Parser names!\n",
      "- Use time 0.000s\n"
     ]
    }
   ],
   "source": [
    "aug_hyp = {\n",
    "            'data_aug_prespective_p': 1.0,\n",
    "            'data_aug_scale': 0.,\n",
    "            'data_aug_shear': 0,\n",
    "            'data_aug_translate': 0.5,\n",
    "            'data_aug_degree': 0,\n",
    "            'data_aug_prespective': False,\n",
    "            'data_aug_hsv_p': 1,\n",
    "            \"data_aug_hsv_hgain\": 0.015,\n",
    "            \"data_aug_hsv_sgain\": 0.7,\n",
    "            \"data_aug_hsv_vgain\": 0.4,\n",
    "            'data_aug_mixup_p': 0.0,\n",
    "            'data_aug_fliplr_p': 0,\n",
    "            'data_aug_flipud_p': 0,\n",
    "            'data_aug_fill_value': 128,\n",
    "            'data_aug_mosaic_p': 1., \n",
    "            \"data_aug_cutout_p\": 1.0, \n",
    "            \"data_aug_cutout_iou_thr\": 0.2, \n",
    "            \"data_aug_scale_jitting_p\": 0.1, \n",
    "            'input_img_size': 448,\n",
    "}\n",
    "\n",
    "img_dir = '../../Dataset/COCO/val/img'\n",
    "lab_dir = \"../../Dataset/COCO/val/lab\"\n",
    "name_path = '../../Dataset/COCO/val/names.txt'\n",
    "input_dim = [448, 448]\n",
    "cache_num = 20\n",
    "enable_data_aug = True\n",
    "seed = 7\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "pin_memory = True\n",
    "shuffle = True\n",
    "drop_last = False\n",
    "\n",
    "\n",
    "dataset, dataloader, prefetcher = build_dataloader(img_dir, lab_dir, name_path, input_dim, aug_hyp, cache_num, \n",
    "                                                    enable_data_aug, seed, batch_size, num_workers, pin_memory, shuffle, drop_last)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = np.random.randint(0, len(dataset))\n",
    "x = dataset.pull_item(img_id)\n",
    "ann = x[1]\n",
    "img = x[0]\n",
    "# img = img.permute(1, 2, 0)\n",
    "# img = np.clip(img * 255.0, 0.0, 255.0)\n",
    "img_mdy = np.ascontiguousarray(img.astype('uint8'))\n",
    "h, w, _ = img.shape\n",
    "save_path = current_work_directionary / \"result\" / \"tmp\" / f\"batch_img_id_{img_id}.png\"\n",
    "dataset.cv2_save_fig(img_mdy, ann['bboxes'], ann['classes'], str(save_path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏            | 8/625 [00:07<10:07,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(dataloader), ncols=50) as t:\n",
    "    for b, x in enumerate(dataloader):\n",
    "        if b == 2:\n",
    "            dataloader.close_data_aug()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            ann = x['ann'][i]\n",
    "            title = x['img_id'][i]\n",
    "            img = x['img'][i]\n",
    "            img = img.permute(1, 2, 0)\n",
    "            img = np.clip(img * 255.0, 0.0, 255.0)\n",
    "            img_mdy = np.ascontiguousarray(img.numpy().astype('uint8'))\n",
    "            h, w, _ = img.shape\n",
    "            # 该笔数据中是否有object，ann[:, 4] == -1表示没有object\n",
    "            valid_index = torch.nonzero(ann[:, 4] >= 0, as_tuple=False).squeeze(dim=1)\n",
    "            # 如果该笔数据有object的话，就plot出来\n",
    "            if valid_index.numel() > 0:\n",
    "                ann_mdy = {'bboxes': ann[valid_index][:, :4].numpy(),\n",
    "                            'classes': ann[valid_index][:, 4].numpy().astype('uint8')}\n",
    "            # 如果该笔数据中没有发现object，则打印出图片的路径\n",
    "            else:\n",
    "                ann_mdy = {'bboxes': [], 'classes': []}\n",
    "            save_path = current_work_directionary / \"result\" / \"tmp\" / f\"batch_{b}_idx_{i}.png\"\n",
    "            dataset.cv2_save_fig(img_mdy, ann_mdy['bboxes'], ann_mdy['classes'], str(save_path))\n",
    "            # print(f\"{b*batch_size+i}\\t{len(ann_mdy['bboxes'])}\")\n",
    "        \n",
    "        if b >= 3:\n",
    "            break\n",
    "    t.update(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"./result/coco_test_imgs\"\n",
    "dataset, dataloader, prefetcher = build_test_dataloader(datadir, img_size=640, batch_size=2, num_workers=0)\n",
    "\n",
    "with tqdm(total=len(dataloader), ncols=50) as t:\n",
    "    for b, x in enumerate(dataloader):\n",
    "        for i in range(len(x)):\n",
    "            info = x['resize_info'][i]\n",
    "            img = x['img'][i]\n",
    "            img = img.permute(1, 2, 0)\n",
    "            img = np.clip(img * 255.0, 0.0, 255.0)\n",
    "            img_mdy = np.ascontiguousarray(img.numpy().astype('uint8'))\n",
    "            h, w, _ = img.shape\n",
    "            fig = plt.figure(figsize=[8, 8])\n",
    "            plt.imshow(img_mdy)\n",
    "            plt.show()\n",
    "    t.update(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a00c0a220c6a4fa84f8be1eccff78cca396213150bbb3b308447c2ee397323f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
